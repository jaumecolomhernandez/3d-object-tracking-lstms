{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **New dataset generation**\n",
    "This notebook takes the original alignet dataset and creates the new one. It extracts the different trajectories and redistributes them in a new folder architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_path = '/home/usuario/'\n",
    "\n",
    "datasets_path = os.path.join(home_path, 'project_data', 'datasets')\n",
    "\n",
    "all_datasets = ['SynthCars', 'SynthCarsPersons', 'Synth20', 'Synth20others', 'KITTITrackletsCars', 'KITTITrackletsCarsPersons', 'KITTITrackletsCarsHard', 'KITTITrackletsCarsPersonsHard']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils to fix the json meta files. Convert to array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_arr(value):\n",
    "    \"\"\" Converts a string with float values to an actual list of floats \"\"\"\n",
    "    return [float(name) for name in value.split()]\n",
    "\n",
    "def fix_meta(meta):\n",
    "    \"\"\" Converts all the string coded values to lists \"\"\"\n",
    "    meta['start_position'] = to_arr(meta['start_position'])\n",
    "    meta['end_position'] = to_arr(meta['end_position'])\n",
    "    meta['translation'] = to_arr(meta['translation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Util to plot positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_points(values):\n",
    "    positions_s = {'x':[], 'y':[]}\n",
    "    for obs in values:\n",
    "        positions_s['x'].append(obs['start_position'][0])\n",
    "        positions_s['y'].append(obs['start_position'][1])\n",
    "    positions_e = {'x':[], 'y':[]}\n",
    "    for obs in values:\n",
    "        positions_e['x'].append(obs['end_position'][0])\n",
    "        positions_e['y'].append(obs['end_position'][1])\n",
    "\n",
    "    plt.scatter(positions_s['x'], positions_s['y'])\n",
    "    plt.scatter(positions_e['x'], positions_e['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the synthetic datasets works for us as they don't contain any trajectory. So I will only work in the KITTI datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **KITTI datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Load all the meta.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset path\n",
    "dataset_path = os.path.join(datasets_path, all_datasets[4]) \n",
    "# Loads all jsons and stores them in a list(container)\n",
    "container = list()\n",
    "for i in range(10000):\n",
    "    # Create path and load file\n",
    "    file_path = os.path.join(dataset_path, \"meta\", str(i).zfill(8)+'.json')\n",
    "    with open(file_path) as json_file: meta_dict = json.load(json_file)\n",
    "    # Convert the string to lists\n",
    "    fix_meta(meta_dict)\n",
    "    meta_dict['filename'] = str(i).zfill(8)\n",
    "    # Append to file\n",
    "    container.append(meta_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Slice the files by 'seq' and 'trackids' parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique seq_ids in the list of dicts\n",
    "seqs = list(set(meta['seq'] for meta in container)) \n",
    "\n",
    "# Store the correct meta files in each dict key (seq_ids)\n",
    "seq_metas = {seq: [] for seq in seqs}\n",
    "for meta in container: \n",
    "    seq_metas[meta['seq']].append(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique seq_ids in the list of dicts\n",
    "seqs = list(set(meta['seq'] for meta in container)) \n",
    "\n",
    "# Store the correct meta files in each dict key (seq_ids)\n",
    "seq_metas = {seq: [] for seq in seqs}\n",
    "for meta in container: \n",
    "    seq_metas[meta['seq']].append(meta)\n",
    "\n",
    "seq_track_metas = dict()\n",
    "\n",
    "for seq_id in seq_metas.keys():    \n",
    "    # This is a list containing all the meta dicts of specific seq_id\n",
    "    curr_metas = seq_metas[seq_id] \n",
    "    \n",
    "    # Get unique trackids in the dicts\n",
    "    track_ids = list(set(meta['trackids'][0] for meta in curr_metas)) \n",
    "    \n",
    "    # Store the different metas at each key (track_ids)\n",
    "    track_metas = {idn: [] for idn in track_ids}\n",
    "    for meta in curr_metas: \n",
    "        track_metas[meta['trackids'][0]].append(meta)\n",
    "    \n",
    "    # The seq_id is used as key to store the computed dict\n",
    "    # The output is a dict of dicts\n",
    "    seq_track_metas[seq_id] = track_metas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.Check the resulting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get possible keys for the seq_track_metas double dict\n",
    "key_dict = {key: list(seq_track_metas[key].keys()) for key in seq_track_metas.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Handcheck of the resulting paths\n",
    "plot_points(seq_track_metas[0][12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Export to the desired folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util to create folders\n",
    "import pathlib\n",
    "def mk_folder(path):    \n",
    "    \"\"\" Util to create folder NO COMPLAINS! \"\"\"\n",
    "    pathlib.Path(path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder '/home/usuario/project_data/new_datasets' already exists\n"
     ]
    }
   ],
   "source": [
    "# Create folder (new_datasets)\n",
    "new_path = os.path.join(home_path, 'project_data', 'new_datasets')\n",
    "\n",
    "mk_folder(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different keys to access by\n",
    "key_dict = {key: list(seq_track_metas[key].keys()) for i, key in enumerate(seq_track_metas.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Comment all of this!\n",
    "for seq_id in seq_track_metas.keys():\n",
    "    for track_id in seq_track_metas[seq_id].keys():\n",
    "\n",
    "        curr_folder_path = os.path.join(new_path,str(seq_id),str(track_id))\n",
    "        mk_folder(curr_folder_path)\n",
    "\n",
    "        curr_trajectory = seq_track_metas[seq_id][track_id]\n",
    "\n",
    "        for time_point in curr_trajectory:\n",
    "            outputfile_path = os.path.join(curr_folder_path, f\"{time_point['filename']}.json\")\n",
    "            with open(outputfile_path, 'w') as json_file:\n",
    "                json.dump(time_point, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Convert the code to functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_arr(value):\n",
    "    \"\"\" Converts a string with float values to an actual list of floats \"\"\"\n",
    "    return [float(name) for name in value.split()]\n",
    "\n",
    "def fix_meta(meta):\n",
    "    \"\"\" Converts all the string coded values to lists \"\"\"\n",
    "    meta['start_position'] = to_arr(meta['start_position'])\n",
    "    meta['end_position'] = to_arr(meta['end_position'])\n",
    "    meta['translation'] = to_arr(meta['translation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util to create folders\n",
    "import pathlib\n",
    "def mk_folder(path):    \n",
    "    \"\"\" Util to create folder NO COMPLAINS! \"\"\"\n",
    "    pathlib.Path(path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to store single seq_ids and track_ids to folders\n",
    "def store_single_path(curr_folder_path, curr_trajectory):\n",
    "    for time_point in curr_trajectory:\n",
    "        outputfile_path = os.path.join(curr_folder_path, f\"{time_point['filename']}.json\")\n",
    "        with open(outputfile_path, 'w') as json_file:\n",
    "            json.dump(time_point, json_file, indent=4)\n",
    "    \n",
    "\n",
    "def store_seq(new_path, seq_track_metas):\n",
    "    for seq_id in seq_track_metas.keys():\n",
    "        print(f\"\\tConverting {seq_id}...\")\n",
    "        for track_id in seq_track_metas[seq_id].keys():\n",
    "\n",
    "            curr_folder_path = os.path.join(new_path,str(seq_id),str(track_id))\n",
    "            mk_folder(curr_folder_path)\n",
    "\n",
    "            curr_trajectory = seq_track_metas[seq_id][track_id]\n",
    "\n",
    "            store_single_path(curr_folder_path, curr_trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset path\n",
    "def load_all_metas(dataset_path):\n",
    "    # Loads all jsons and stores them in a list(container)\n",
    "    container = list()\n",
    "    for i in range(10000):\n",
    "        # Create path and load file\n",
    "        file_path = os.path.join(dataset_path, \"meta\", str(i).zfill(8)+'.json')\n",
    "        with open(file_path) as json_file: meta_dict = json.load(json_file)\n",
    "        # Convert the string to lists\n",
    "        fix_meta(meta_dict)\n",
    "        meta_dict['filename'] = str(i).zfill(8)\n",
    "        # Append to file\n",
    "        container.append(meta_dict)\n",
    "    \n",
    "    return container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_seq_track(all_metas): \n",
    "    # Get unique seq_ids in the list of dicts\n",
    "    seqs = list(set(meta['seq'] for meta in all_metas)) \n",
    "\n",
    "    # Store the correct meta files in each dict key (seq_ids)\n",
    "    seq_metas = {seq: [] for seq in seqs}\n",
    "    for meta in all_metas: \n",
    "        seq_metas[meta['seq']].append(meta)\n",
    "\n",
    "    seq_track_metas = dict()\n",
    "\n",
    "    for seq_id in seq_metas.keys():    \n",
    "        # This is a list containing all the meta dicts of specific seq_id\n",
    "        curr_metas = seq_metas[seq_id] \n",
    "\n",
    "        # Get unique trackids in the dicts\n",
    "        track_ids = list(set(meta['trackids'][0] for meta in curr_metas)) \n",
    "\n",
    "        # Store the different metas at each key (track_ids)\n",
    "        track_metas = {idn: [] for idn in track_ids}\n",
    "        for meta in curr_metas: \n",
    "            track_metas[meta['trackids'][0]].append(meta)\n",
    "\n",
    "        # The seq_id is used as key to store the computed dict\n",
    "        # The output is a dict of dicts\n",
    "        seq_track_metas[seq_id] = track_metas\n",
    "    \n",
    "    return seq_track_metas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now converting KITTITrackletsCars\n",
      "\tConverting 0...\n",
      "\tConverting 1...\n",
      "\tConverting 3...\n",
      "\tConverting 4...\n",
      "\tConverting 5...\n",
      "\tConverting 9...\n",
      "\tConverting 11...\n",
      "Now converting KITTITrackletsCarsPersons\n",
      "\tConverting 0...\n",
      "\tConverting 1...\n",
      "\tConverting 3...\n",
      "\tConverting 4...\n",
      "\tConverting 5...\n",
      "\tConverting 9...\n",
      "\tConverting 11...\n",
      "Now converting KITTITrackletsCarsHard\n",
      "\tConverting 0...\n",
      "\tConverting 1...\n",
      "\tConverting 4...\n",
      "\tConverting 9...\n",
      "\tConverting 12...\n",
      "\tConverting 15...\n",
      "\tConverting 20...\n",
      "Now converting KITTITrackletsCarsPersonsHard\n",
      "\tConverting 0...\n",
      "\tConverting 1...\n",
      "\tConverting 4...\n",
      "\tConverting 9...\n",
      "\tConverting 12...\n",
      "\tConverting 15...\n",
      "\tConverting 19...\n",
      "\tConverting 20...\n"
     ]
    }
   ],
   "source": [
    "# Path definition\n",
    "home_path = '/home/usuario/'\n",
    "datasets_path = os.path.join(home_path, 'project_data', 'datasets')\n",
    "new_path = os.path.join(home_path, 'project_data', 'new_datasets')\n",
    "\n",
    "# This are all the KITTI datasets we can use\n",
    "KITTIDatasets = ['KITTITrackletsCars', 'KITTITrackletsCarsPersons', 'KITTITrackletsCarsHard', 'KITTITrackletsCarsPersonsHard']\n",
    "\n",
    "\n",
    "for name in KITTIDatasets:\n",
    "    print(f\"Now converting {name}\")\n",
    "    \n",
    "    # 1.Load all metas from dataset\n",
    "    # datasets_path should be from class\n",
    "    dataset_path = os.path.join(datasets_path, name)\n",
    "    all_metas = load_all_metas(dataset_path)\n",
    "    \n",
    "    # 2.Slice datasets by seq_id and track_id\n",
    "    seq_track_metas = slice_seq_track(all_metas)\n",
    "    \n",
    "    # 3.Store paths\n",
    "    # Create paths and folder\n",
    "    destination_path = os.path.join(new_path, name)\n",
    "    mk_folder(new_path)\n",
    "    \n",
    "    store_seq(destination_path, seq_track_metas)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
