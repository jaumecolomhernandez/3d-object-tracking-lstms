{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **New dataset generation**\n",
    "This notebook takes the original alignet dataset and creates the new one. It extracts the different trajectories and redistributes them in a new folder architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_path = '/home/usuario/'\n",
    "\n",
    "datasets_path = os.path.join(home_path, 'project_data', 'datasets')\n",
    "\n",
    "all_datasets = ['SynthCars', 'SynthCarsPersons', 'Synth20', 'Synth20others', 'KITTITrackletsCars', 'KITTITrackletsCarsPersons', 'KITTITrackletsCarsHard', 'KITTITrackletsCarsPersonsHard']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils to fix the json meta files. Convert to array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_arr(value):\n",
    "    \"\"\" Converts a string with float values to an actual list of floats \"\"\"\n",
    "    return [float(name) for name in value.split()]\n",
    "\n",
    "def fix_meta(meta):\n",
    "    \"\"\" Converts all the string coded values to lists \"\"\"\n",
    "    meta['start_position'] = to_arr(meta['start_position'])\n",
    "    meta['end_position'] = to_arr(meta['end_position'])\n",
    "    meta['translation'] = to_arr(meta['translation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Util to plot positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_points(values):\n",
    "    positions_s = {'x':[], 'y':[]}\n",
    "    for obs in values:\n",
    "        positions_s['x'].append(obs['start_position'][0])\n",
    "        positions_s['y'].append(obs['start_position'][1])\n",
    "    positions_e = {'x':[], 'y':[]}\n",
    "    for obs in values:\n",
    "        positions_e['x'].append(obs['end_position'][0])\n",
    "        positions_e['y'].append(obs['end_position'][1])\n",
    "\n",
    "    plt.scatter(positions_s['x'], positions_s['y'])\n",
    "    plt.scatter(positions_e['x'], positions_e['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the synthetic datasets works for us as they don't contain any trajectory. So I will only work in the KITTI datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **KITTI datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Load all the meta.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset path\n",
    "dataset_path = os.path.join(datasets_path, all_datasets[4]) \n",
    "# Loads all jsons and stores them in a list(container)\n",
    "container = list()\n",
    "for i in range(10000):\n",
    "    # Create path and load file\n",
    "    file_path = os.path.join(dataset_path, \"meta\", str(i).zfill(8)+'.json')\n",
    "    with open(file_path) as json_file: meta_dict = json.load(json_file)\n",
    "    # Convert the string to lists\n",
    "    fix_meta(meta_dict)\n",
    "    meta_dict['filename'] = str(i).zfill(8)\n",
    "    # Append to file\n",
    "    container.append(meta_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Slice the files by 'seq' and 'trackids' parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique seq_ids in the list of dicts\n",
    "seqs = list(set(meta['seq'] for meta in container)) \n",
    "\n",
    "# Store the correct meta files in each dict key (seq_ids)\n",
    "seq_metas = {seq: [] for seq in seqs}\n",
    "for meta in container: \n",
    "    seq_metas[meta['seq']].append(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique seq_ids in the list of dicts\n",
    "seqs = list(set(meta['seq'] for meta in container)) \n",
    "\n",
    "# Store the correct meta files in each dict key (seq_ids)\n",
    "seq_metas = {seq: [] for seq in seqs}\n",
    "for meta in container: \n",
    "    seq_metas[meta['seq']].append(meta)\n",
    "\n",
    "seq_track_metas = dict()\n",
    "\n",
    "for seq_id in seq_metas.keys():    \n",
    "    # This is a list containing all the meta dicts of specific seq_id\n",
    "    curr_metas = seq_metas[seq_id] \n",
    "    \n",
    "    # Get unique trackids in the dicts\n",
    "    track_ids = list(set(meta['trackids'][0] for meta in curr_metas)) \n",
    "    \n",
    "    # Store the different metas at each key (track_ids)\n",
    "    track_metas = {idn: [] for idn in track_ids}\n",
    "    for meta in curr_metas: \n",
    "        track_metas[meta['trackids'][0]].append(meta)\n",
    "    \n",
    "    # The seq_id is used as key to store the computed dict\n",
    "    # The output is a dict of dicts\n",
    "    seq_track_metas[seq_id] = track_metas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.Check the resulting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get possible keys for the seq_track_metas double dict\n",
    "key_dict = {key: list(seq_track_metas[key].keys()) for key in seq_track_metas.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Handcheck of the resulting paths\n",
    "plot_points(seq_track_metas[4][30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Export to the desired folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util to create folders\n",
    "import pathlib\n",
    "def mk_folder(path):    \n",
    "    \"\"\" Util to create folder NO COMPLAINS! \"\"\"\n",
    "    pathlib.Path(path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder (new_datasets)\n",
    "new_path = os.path.join(home_path, 'project_data', 'new_datasets')\n",
    "\n",
    "mk_folder(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different keys to access by\n",
    "key_dict = {key: list(seq_track_metas[key].keys()) for i, key in enumerate(seq_track_metas.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Comment all of this!\n",
    "for seq_id in seq_track_metas.keys():\n",
    "    for track_id in seq_track_metas[seq_id].keys():\n",
    "\n",
    "        curr_folder_path = os.path.join(new_path,str(seq_id),str(track_id))\n",
    "        mk_folder(curr_folder_path)\n",
    "\n",
    "        curr_trajectory = seq_track_metas[seq_id][track_id]\n",
    "\n",
    "        for time_point in curr_trajectory:\n",
    "            outputfile_path = os.path.join(curr_folder_path, f\"{time_point['filename']}.json\")\n",
    "            with open(outputfile_path, 'w') as json_file:\n",
    "                json.dump(time_point, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Convert the code to functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_arr(value):\n",
    "    \"\"\" Converts a string with float values to an actual list of floats \"\"\"\n",
    "    return [float(name) for name in value.split()]\n",
    "\n",
    "def fix_meta(meta):\n",
    "    \"\"\" Converts all the string coded values to lists \"\"\"\n",
    "    meta['start_position'] = to_arr(meta['start_position'])\n",
    "    meta['end_position'] = to_arr(meta['end_position'])\n",
    "    meta['translation'] = to_arr(meta['translation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util to create folders\n",
    "import pathlib\n",
    "def mk_folder(path):    \n",
    "    \"\"\" Util to create folder NO COMPLAINS! \"\"\"\n",
    "    pathlib.Path(path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to store single seq_ids and track_ids to folders\n",
    "def store_single_path(curr_folder_path, curr_trajectory):\n",
    "    for time_point in curr_trajectory:\n",
    "        outputfile_path = os.path.join(curr_folder_path, f\"{time_point['filename']}.json\")\n",
    "        with open(outputfile_path, 'w') as json_file:\n",
    "            json.dump(time_point, json_file, indent=4)\n",
    "    \n",
    "\n",
    "def store_seq(new_path, seq_track_metas):\n",
    "    for seq_id in seq_track_metas.keys():\n",
    "        print(f\"\\tConverting {seq_id}...\")\n",
    "        for track_id in seq_track_metas[seq_id].keys():\n",
    "\n",
    "            curr_folder_path = os.path.join(new_path,str(seq_id),str(track_id))\n",
    "            mk_folder(curr_folder_path)\n",
    "\n",
    "            curr_trajectory = seq_track_metas[seq_id][track_id]\n",
    "\n",
    "            store_single_path(curr_folder_path, curr_trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset path\n",
    "def load_all_metas(dataset_path):\n",
    "    # Loads all jsons and stores them in a list(container)\n",
    "    container = list()\n",
    "    meta_path = os.path.join(dataset_path, \"meta\")\n",
    "    for filename in sorted(os.listdir(meta_path)):\n",
    "        # Create path and load file\n",
    "        file_path = os.path.join(meta_path, filename)\n",
    "        with open(file_path) as json_file: meta_dict = json.load(json_file)\n",
    "        # Convert the string to lists\n",
    "        fix_meta(meta_dict)\n",
    "        meta_dict['filename'] = filename[:-5]\n",
    "        # Append to file\n",
    "        container.append(meta_dict)\n",
    "    \n",
    "    return container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_seq_track(all_metas): \n",
    "    # Get unique seq_ids in the list of dicts\n",
    "    seqs = list(set(meta['seq'] for meta in all_metas)) \n",
    "\n",
    "    # Store the correct meta files in each dict key (seq_ids)\n",
    "    seq_metas = {seq: [] for seq in seqs}\n",
    "    for meta in all_metas: \n",
    "        seq_metas[meta['seq']].append(meta)\n",
    "\n",
    "    seq_track_metas = dict()\n",
    "\n",
    "    for seq_id in seq_metas.keys():    \n",
    "        # This is a list containing all the meta dicts of specific seq_id\n",
    "        curr_metas = seq_metas[seq_id] \n",
    "\n",
    "        # Get unique trackids in the dicts\n",
    "        track_ids = list(set(meta['trackids'][0] for meta in curr_metas)) \n",
    "\n",
    "        # Store the different metas at each key (track_ids)\n",
    "        track_metas = {idn: [] for idn in track_ids}\n",
    "        for meta in curr_metas: \n",
    "            track_metas[meta['trackids'][0]].append(meta)\n",
    "\n",
    "        # The seq_id is used as key to store the computed dict\n",
    "        # The output is a dict of dicts\n",
    "        seq_track_metas[seq_id] = track_metas\n",
    "    \n",
    "    return seq_track_metas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_name_container(seq_track_metas):\n",
    "    \"\"\"  \"\"\"\n",
    "    name_container = dict()\n",
    "    for seq_id in seq_track_metas.keys():\n",
    "        for track_id in seq_track_metas[seq_id].keys():\n",
    "            names = [meta['filename'] for meta in seq_track_metas[0][0]]\n",
    "            name_container[f'{seq_id}_{track_id}'] = names\n",
    "            \n",
    "    return name_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_cont = create_name_container(seq_track_metas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('name_container.txt', 'w') as outfile:\n",
    "    json.dump(name_cont, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now converting KITTITrackletsCars\n",
      "\tConverting 0...\n",
      "\tConverting 1...\n",
      "\tConverting 2...\n",
      "\tConverting 3...\n",
      "\tConverting 4...\n",
      "\tConverting 5...\n",
      "\tConverting 6...\n",
      "\tConverting 7...\n",
      "\tConverting 8...\n",
      "\tConverting 9...\n",
      "\tConverting 10...\n",
      "\tConverting 11...\n",
      "\tConverting 12...\n",
      "\tConverting 13...\n",
      "\tConverting 14...\n",
      "\tConverting 15...\n",
      "\tConverting 16...\n",
      "\tConverting 18...\n",
      "\tConverting 19...\n",
      "\tConverting 20...\n",
      "Now converting KITTITrackletsCarsPersons\n",
      "\tConverting 0...\n",
      "\tConverting 1...\n",
      "\tConverting 2...\n",
      "\tConverting 3...\n",
      "\tConverting 4...\n",
      "\tConverting 5...\n",
      "\tConverting 6...\n",
      "\tConverting 7...\n",
      "\tConverting 8...\n",
      "\tConverting 9...\n",
      "\tConverting 10...\n",
      "\tConverting 11...\n",
      "\tConverting 12...\n",
      "\tConverting 13...\n",
      "\tConverting 14...\n",
      "\tConverting 15...\n",
      "\tConverting 16...\n",
      "\tConverting 17...\n",
      "\tConverting 18...\n",
      "\tConverting 19...\n",
      "\tConverting 20...\n",
      "Now converting KITTITrackletsCarsHard\n",
      "\tConverting 0...\n",
      "\tConverting 1...\n",
      "\tConverting 2...\n",
      "\tConverting 4...\n",
      "\tConverting 7...\n",
      "\tConverting 9...\n",
      "\tConverting 12...\n",
      "\tConverting 14...\n",
      "\tConverting 15...\n",
      "\tConverting 20...\n",
      "Now converting KITTITrackletsCarsPersonsHard\n",
      "\tConverting 0...\n",
      "\tConverting 1...\n",
      "\tConverting 2...\n",
      "\tConverting 4...\n",
      "\tConverting 7...\n",
      "\tConverting 9...\n",
      "\tConverting 12...\n",
      "\tConverting 13...\n",
      "\tConverting 14...\n",
      "\tConverting 15...\n",
      "\tConverting 16...\n",
      "\tConverting 19...\n",
      "\tConverting 20...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Path definition\n",
    "home_path = '/home/usuario/'\n",
    "datasets_path = os.path.join(home_path, 'project_data', 'datasets')\n",
    "new_path = os.path.join(home_path, 'project_data', 'new_datasets')\n",
    "\n",
    "# This are all the KITTI datasets we can use\n",
    "KITTIDatasets = ['KITTITrackletsCars', 'KITTITrackletsCarsPersons', 'KITTITrackletsCarsHard', 'KITTITrackletsCarsPersonsHard']\n",
    "\n",
    "\n",
    "for name in KITTIDatasets:\n",
    "    print(f\"Now converting {name}\")\n",
    "    \n",
    "    # 1.Load all metas from dataset\n",
    "    # datasets_path should be from class\n",
    "    dataset_path = os.path.join(datasets_path, name)\n",
    "    all_metas = load_all_metas(dataset_path)\n",
    "    \n",
    "    # 2.Slice datasets by seq_id and track_id\n",
    "    seq_track_metas = slice_seq_track(all_metas)\n",
    "    \n",
    "    # 3.Store paths\n",
    "    # Create paths and folder\n",
    "    destination_path = os.path.join(new_path, name)\n",
    "    mk_folder(new_path)\n",
    "    \n",
    "    store_seq(destination_path, seq_track_metas)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Info CSV**\n",
    "In this section we create a CSV file with necessary information about the paths. We need to know if a path is evaluation or training (at least on the original model), I also add the number of datapoints and its cumulative sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to load data from new datasets\n",
    "def read_paths(filepath):\n",
    "    \"\"\" Read path json file from filepath \"\"\"\n",
    "    with open(filepath) as file:\n",
    "        name_cont = json.load(file)\n",
    "    return name_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create paths\n",
    "new_path = os.path.join(home_path, 'project_data', 'new_datasets')   \n",
    "dataset_name = all_datasets[6]\n",
    "json_path = os.path.join(new_path, dataset_name, f\"{dataset_name}_path.json\")\n",
    "\n",
    "# Load info json\n",
    "info = read_paths(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data containers\n",
    "cumsum = 0\n",
    "name_list = list()\n",
    "container = np.zeros((len(info), 4), dtype=int)\n",
    "\n",
    "# Iterate through every of them\n",
    "for i, vtuple in enumerate((info.items())):\n",
    "    # Append name\n",
    "    name_list.append(vtuple[0])\n",
    "    \n",
    "    # Compute index values\n",
    "    container[i,2:4] = [len(vtuple[1]), cumsum]\n",
    "    cumsum = cumsum + len(vtuple[1])\n",
    "\n",
    "# Create dataframe and complete with info\n",
    "df_all = pd.DataFrame(container, columns=['name', 'type', 'n_points', 'cumsum_n_points'])\n",
    "df_all['name'] = name_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are only missing the info about the type of the path (training or evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path creation\n",
    "dataset_path = os.path.join(datasets_path, all_datasets[4], 'split')\n",
    "# Load the info json\n",
    "indexes = np.loadtxt(os.path.join(dataset_path, 'val.txt'), dtype=int)\n",
    "\n",
    "# Set type of path\n",
    "df_all.loc[df_all['cumsum_n_points'] < indexes[0], 'type'] = 'T'\n",
    "df_all.loc[df_all['cumsum_n_points'] >= indexes[0], 'type'] = 'E'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into Training and Evaluation dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/.conda/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Select the evaluation entries (pick the larger than the first eval index!)\n",
    "df_train = df_all[df_all['cumsum_n_points'] < indexes[0]]\n",
    "df_val = df_all[df_all['cumsum_n_points'] >= indexes[0]]\n",
    "\n",
    "# Fix the cumulative sum parameters\n",
    "df_val['cumsum_n_points'] -= df_val.iloc[0,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_info_df(dataset_name):\n",
    "    \"\"\"  \"\"\"\n",
    "    # Create paths\n",
    "    datasets_path = os.path.join(home_path, 'project_data', 'datasets')\n",
    "    new_path = os.path.join(home_path, 'project_data', 'new_datasets')   \n",
    "    json_path = os.path.join(new_path, dataset_name, f\"{dataset_name}_path.json\")\n",
    "\n",
    "    # Load info json\n",
    "    info = read_paths(json_path)\n",
    "    \n",
    "    # data containers\n",
    "    cumsum = 0\n",
    "    name_list = list()\n",
    "    container = np.zeros((len(info), 4), dtype=int)\n",
    "\n",
    "    # Iterate through every of them\n",
    "    for i, vtuple in enumerate((info.items())):\n",
    "        # Append name\n",
    "        name_list.append(vtuple[0])\n",
    "\n",
    "        # Compute index values\n",
    "        container[i,2:4] = [len(vtuple[1]), cumsum]\n",
    "        cumsum = cumsum + len(vtuple[1])\n",
    "\n",
    "    # Create dataframe and complete with info\n",
    "    df_all = pd.DataFrame(container, columns=['name', 'type', 'n_points', 'cumsum_n_points'])\n",
    "    df_all['name'] = name_list\n",
    "    \n",
    "    # Split path creation\n",
    "    dataset_path = os.path.join(datasets_path, dataset_name, 'split')\n",
    "    # Load split info\n",
    "    indexes = np.loadtxt(os.path.join(dataset_path, 'val.txt'), dtype=int)\n",
    "\n",
    "    # Set type of path\n",
    "    df_all.loc[df_all['cumsum_n_points'] < indexes[0], 'type'] = 'T'\n",
    "    df_all.loc[df_all['cumsum_n_points'] >= indexes[0], 'type'] = 'E'\n",
    "    \n",
    "    # Select the evaluation entries (pick the larger than the first eval index!)\n",
    "    df_train = df_all[df_all['cumsum_n_points'] < indexes[0]]\n",
    "    df_val = df_all[df_all['cumsum_n_points'] >= indexes[0]]\n",
    "\n",
    "    # Fix the cumulative sum parameters\n",
    "    df_val['cumsum_n_points'] -= df_val.iloc[0,3]\n",
    "    \n",
    "    return df_train, df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/.conda/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val = create_info_df(all_datasets[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = os.path.join(new_path, all_datasets[6])\n",
    "mk_folder(dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(os.path.join(dataset_folder, f\"{all_datasets[6]}_info.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
