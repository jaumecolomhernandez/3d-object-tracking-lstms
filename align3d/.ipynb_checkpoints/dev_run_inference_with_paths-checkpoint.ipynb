{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Run inference with paths**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution line   \n",
    "`python train.py eval_only --config configs/KITTITrackletsCarsHard.json --eval_epoch 28`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/usuario/.conda/envs/thesis/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# Necessary imports\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "#import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "tp_path = os.path.join('/home/usuario/project/align3d', 'tp_utils')\n",
    "sys.path.insert(0, tp_path)\n",
    "\n",
    "import provider\n",
    "import copy\n",
    "import models.tp8 as MODEL_tp8\n",
    "from config import load_config, configGlobal, save_config\n",
    "\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config and model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = Namespace(config='configs/KITTITrackletsCarsHard.json', \n",
    "                  eval_epoch='28', \n",
    "                  its=30, \n",
    "                  operation='eval_only', \n",
    "                  refineICP=False, \n",
    "                  refineICPmethod='p2p', \n",
    "                  use_old_results=False)\n",
    "load_config(FLAGS.config)\n",
    "\n",
    "# temp fix\n",
    "TRAIN_INDICES = provider.getDataFiles(f'{configGlobal.data.basepath}/split/train.txt')\n",
    "VAL_INDICES = provider.getDataFiles(f'{configGlobal.data.basepath}/split/val.txt')[:200]\n",
    "configGlobal.data.__dict__[\"ntrain\"] = len(TRAIN_INDICES)\n",
    "configGlobal.data.__dict__[\"nval\"] = len(VAL_INDICES)\n",
    "\n",
    "cfg = configGlobal\n",
    "\n",
    "MODEL = MODEL_tp8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_only_model_to_load=None\n",
    "eval_only=True\n",
    "eval_epoch=FLAGS.eval_epoch\n",
    "do_timings=False\n",
    "override_batch_size=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/usuario/project/align3d/utils/tf_util.py:574: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/usuario/project/align3d/models/tp8.py:215: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /home/usuario/project/align3d/models/tp8.py:205: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Restoring parameters from /home/usuario/project_data/trained/KITTITrackletsCarsHard/model-28\n",
      "----- Samples 0/200 -----\n",
      "0.06755182147026062\n",
      "Results stored\n",
      "----- Samples 128/200 -----\n",
      "nan\n",
      "Results stored\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    \n",
    "    # Define model on the device\n",
    "    with tf.device('/gpu:' + str(cfg.gpu_index)):\n",
    "        pcs1, pcs2, translations, rel_angles, pc1centers, pc2centers, pc1angles, pc2angles = MODEL.placeholder_inputs(cfg.training.batch_size, cfg.model.num_points)\n",
    "        is_training_pl = tf.placeholder(tf.bool, shape=())\n",
    "\n",
    "        # Note the global_step=batch parameter to minimize.\n",
    "        # That tells the optimizer to helpfully increment the 'batch' parameter for you every time it trains.\n",
    "        batch = tf.Variable(0)\n",
    "        #bn_decay = get_bn_decay(batch)\n",
    "        \n",
    "        # Get model and loss\n",
    "        end_points = MODEL.get_model(pcs1, pcs2, is_training_pl)\n",
    "        loss = MODEL.get_loss(pcs1, pcs2, translations, rel_angles, pc1centers, pc2centers, pc1angles, pc2angles, end_points)\n",
    "\n",
    "        # Add ops to save and restore all the variables.\n",
    "        saver = tf.train.Saver(max_to_keep=1000)\n",
    "        \n",
    "    # Create a session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.allow_soft_placement = True\n",
    "    config.log_device_placement = False\n",
    "    \n",
    "    sess = tf.Session(config=config)\n",
    "    \n",
    "    merged = tf.summary.merge_all() # Necessary to run\n",
    "\n",
    "\n",
    "    # Init variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    # To fix the bug introduced in TF 0.12.1 as in\n",
    "    # http://stackoverflow.com/questions/41543774/invalidargumenterror-for-tensor-bool-tensorflow-0-12-1\n",
    "    # sess.run(init)\n",
    "    sess.run(init, {is_training_pl: True})\n",
    "    \n",
    "    ops = {'pcs1': pcs1, # INPUT\n",
    "           'pcs2': pcs2, # INPUT\n",
    "           'translations': translations, # GT \n",
    "           'rel_angles': rel_angles,     # gt\n",
    "           'is_training_pl': is_training_pl, # What is it for?\n",
    "           'pred_translations': end_points['pred_translations'], \n",
    "           'pred_remaining_angle_logits': end_points['pred_remaining_angle_logits'], \n",
    "           'pc1centers': pc1centers,     # GT\n",
    "           'pc2centers': pc2centers,     # GT\n",
    "           'pc1angles': pc1angles,       # GT\n",
    "           'pc2angles': pc2angles,       # GT\n",
    "           'pred_s1_pc1centers': end_points['pred_s1_pc1centers'], \n",
    "           'pred_s1_pc2centers': end_points['pred_s1_pc2centers'], \n",
    "           'pred_s2_pc1centers': end_points['pred_s2_pc1centers'], \n",
    "           'pred_s2_pc2centers': end_points['pred_s2_pc2centers'], \n",
    "           'pred_pc1angle_logits': end_points['pred_pc1angle_logits'], \n",
    "           'pred_pc2angle_logits': end_points['pred_pc2angle_logits'], \n",
    "           'loss': loss,                 # COMPUTED\n",
    "           'merged': merged}             # WHAT IS THIS??\n",
    "           #'train_op': train_op, \n",
    "           #'step': batch}                # INFO\n",
    "\n",
    "    \n",
    "    # Load existing model!!!!!!!!!!!!!!!!!!!!!\n",
    "    model_to_load = cfg.logging.logdir\n",
    "    assert os.path.isfile(f'{model_to_load}/model-{eval_epoch}.index'), f'{model_to_load}/model-{eval_epoch}.index'\n",
    "    saver.restore(sess, f'{model_to_load}/model-{eval_epoch}')\n",
    "    \n",
    "    start_epoch = int(eval_epoch)\n",
    "    epoch = start_epoch\n",
    "    \n",
    "    num_batches_per_epoch = len(TRAIN_INDICES) // cfg.training.batch_size\n",
    "    \n",
    "    is_training = False\n",
    "    batch_size = cfg.training.batch_size\n",
    "\n",
    "    val_idxs = VAL_INDICES\n",
    "    num_batches = int(np.ceil(len(val_idxs) / batch_size))\n",
    "    num_full_batches = int(np.floor(len(val_idxs) / batch_size))\n",
    "\n",
    "    loss_sum = 0\n",
    "    #global_step = sess.run([ops['step']])[0]\n",
    "    \n",
    "    #  step_in_epochs = epoch + 1\n",
    "    eval_dir = f'{cfg.logging.logdir}/val/eval{str(epoch).zfill(6)}'\n",
    "    base_eval_dir = eval_dir\n",
    "    if FLAGS.refineICP:\n",
    "        eval_dir = f'{eval_dir}/refined_{FLAGS.refineICPmethod}{\"_\"+FLAGS.its if FLAGS.its != 30 else \"\"}'\n",
    "\n",
    "    if os.path.isdir(eval_dir):\n",
    "        os.rename(eval_dir, f'{eval_dir}_backup_{int(time.time())}')\n",
    "\n",
    "    os.makedirs(eval_dir, exist_ok=True)\n",
    "\n",
    "    # Prediction containers\n",
    "    all_pred_translations = np.empty((len(val_idxs), 3), dtype=np.float32)\n",
    "    all_pred_angles = np.empty((len(val_idxs), 1), dtype=np.float32)\n",
    "    \n",
    "    # The conversion from logits to is done outside the model\n",
    "    # Pass this to the model!\n",
    "    all_pred_s2_pc1angles = np.empty((len(val_idxs), 1), dtype=np.float32)\n",
    "    all_pred_s2_pc2angles = np.empty((len(val_idxs), 1), dtype=np.float32)\n",
    "    \n",
    "    # Ground truth contina\n",
    "    all_gt_translations = np.empty((len(val_idxs), 3), dtype=np.float32)\n",
    "    all_gt_angles = np.empty((len(val_idxs), 1), dtype=np.float32)\n",
    "    all_gt_pc1centers = np.empty((len(val_idxs), 3), dtype=np.float32)\n",
    "    \n",
    "    cumulated_times = 0.\n",
    "    for batch_idx in range(num_batches):\n",
    "        \n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min((batch_idx + 1) * batch_size, len(val_idxs))\n",
    "        \n",
    "        print(f'----- Samples {start_idx}/{len(VAL_INDICES)} -----')\n",
    "        \n",
    "        # TODO: Create a class to solve this shit\n",
    "        pcs1, pcs2, translations, rel_angles, pc1centers, pc2centers, pc1angles, pc2angles = provider.load_batch(val_idxs[start_idx:end_idx])\n",
    "\n",
    "        # TODO: Investigate a better way to do this feed_dict\n",
    "        feed_dict = {\n",
    "            ops['pcs1']: pcs1,\n",
    "            ops['pcs2']: pcs2,\n",
    "            ops['translations']: translations,\n",
    "            ops['rel_angles']: rel_angles,\n",
    "            ops['is_training_pl']: is_training,\n",
    "            ops['pc1centers']: pc1centers,\n",
    "            ops['pc2centers']: pc2centers,\n",
    "            ops['pc1angles']: pc1angles,\n",
    "            ops['pc2angles']: pc2angles,\n",
    "        }\n",
    "        start = time.time()\n",
    "        \n",
    "        # TODO: IDEM Create class to solve this mess\n",
    "        summary, loss_val, pred_translations,pred_pc1angle_logits, pred_pc2angle_logits, pred_remaining_angle_logits, _, _, _, _ = sess.run([ops['merged'], ops['loss'], ops['pred_translations'], ops['pred_pc1angle_logits'], ops['pred_pc2angle_logits'], ops['pred_remaining_angle_logits'], ops['pred_s1_pc1centers'], ops['pred_s1_pc2centers'], ops['pred_s2_pc1centers'], ops['pred_s2_pc2centers']], feed_dict=feed_dict)\n",
    "        \n",
    "        # Why do we need time?\n",
    "        cumulated_times += time.time() - start\n",
    "        # ?\n",
    "        actual_batch_size = end_idx - start_idx\n",
    "        \n",
    "        # How can this be longer? Maybe when not full batch\n",
    "        pred_translations = pred_translations[:actual_batch_size]\n",
    "        # Correct from logits to angle\n",
    "        pred_angles_pc1 = MODEL.classLogits2angle(pred_pc1angle_logits[:actual_batch_size])\n",
    "        pred_angles_pc2 = MODEL.classLogits2angle(pred_pc2angle_logits[:actual_batch_size])\n",
    "        pred_angles_remaining = MODEL.classLogits2angle(pred_remaining_angle_logits[:actual_batch_size])\n",
    "        # Final angle computation\n",
    "        pred_angles = pred_angles_pc2 - pred_angles_pc1 + pred_angles_remaining\n",
    "        \n",
    "        # Why this?\n",
    "        if actual_batch_size == batch_size:  # last batch is not counted\n",
    "            loss_sum += loss_val\n",
    "        \n",
    "        # Some parameters (ARE THEY NEEDED?)\n",
    "        mean_per_transform_loss = loss_sum / num_full_batches if num_full_batches > 0 else 0.\n",
    "        mean_execution_time = cumulated_times / float(len(val_idxs))\n",
    "        \n",
    "        print(f\"{loss_val}\")\n",
    "        \n",
    "        # Store result to big array TODO: CONVERT TO SINGLE LINE OP\n",
    "        for idx in range(actual_batch_size):\n",
    "            global_idx = start_idx + idx\n",
    "\n",
    "            all_pred_translations[global_idx] = pred_translations[idx]\n",
    "            all_pred_angles[global_idx] = pred_angles[idx]\n",
    "\n",
    "            all_gt_translations[global_idx] = translations[idx]\n",
    "            all_gt_angles[global_idx] = rel_angles[idx]\n",
    "            all_gt_pc1centers[global_idx] = pc1centers[idx]\n",
    "        \n",
    "        print(\"Results stored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pred_angles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
