{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Run inference with paths**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution line   \n",
    "`python train.py eval_only --config configs/KITTITrackletsCarsHard.json --eval_epoch 28`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/usuario/.conda/envs/thesis/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# Necessary imports\n",
    "import argparse\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "tp_path = os.path.join('/home/usuario/project/align3d', 'tp_utils')\n",
    "sys.path.insert(0, tp_path)\n",
    "\n",
    "import provider\n",
    "import copy\n",
    "import models.tp8 as MODEL_tp8\n",
    "from config import load_config, configGlobal, save_config\n",
    "\n",
    "from argparse import Namespace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_path = os.path.join('/home/usuario/project/align3d', 'tp_utils')\n",
    "sys.path.insert(0, tp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import provider\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config and model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictFLAGS = {'config': 'configs/KITTITrackletsCarsHard.json', \n",
    "             'eval_epoch':'28'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20000,\n",
       " 20001,\n",
       " 20002,\n",
       " 20003,\n",
       " 20004,\n",
       " 20005,\n",
       " 20006,\n",
       " 20007,\n",
       " 20008,\n",
       " 20009,\n",
       " 20010,\n",
       " 20011,\n",
       " 20012,\n",
       " 20013,\n",
       " 20014,\n",
       " 20015,\n",
       " 20016,\n",
       " 20017,\n",
       " 20018,\n",
       " 20019,\n",
       " 20020,\n",
       " 20021,\n",
       " 20022,\n",
       " 20023,\n",
       " 20024,\n",
       " 20025,\n",
       " 20026,\n",
       " 20027,\n",
       " 20028,\n",
       " 20029,\n",
       " 20030,\n",
       " 20031,\n",
       " 20032,\n",
       " 20033,\n",
       " 20034,\n",
       " 20035,\n",
       " 20036,\n",
       " 20037,\n",
       " 20038,\n",
       " 20039,\n",
       " 20040,\n",
       " 20041,\n",
       " 20042,\n",
       " 20043,\n",
       " 20044,\n",
       " 20045,\n",
       " 20046,\n",
       " 20047,\n",
       " 20048,\n",
       " 20049,\n",
       " 20050,\n",
       " 20051,\n",
       " 20052,\n",
       " 20053,\n",
       " 20054,\n",
       " 20055,\n",
       " 20056,\n",
       " 20057,\n",
       " 20058,\n",
       " 20059,\n",
       " 20060,\n",
       " 20061,\n",
       " 20062,\n",
       " 20063,\n",
       " 20064,\n",
       " 20065,\n",
       " 20066,\n",
       " 20067,\n",
       " 20068,\n",
       " 20069,\n",
       " 20070,\n",
       " 20071,\n",
       " 20072,\n",
       " 20073,\n",
       " 20074,\n",
       " 20075,\n",
       " 20076,\n",
       " 20077,\n",
       " 20078,\n",
       " 20079,\n",
       " 20080,\n",
       " 20081,\n",
       " 20082,\n",
       " 20083,\n",
       " 20084,\n",
       " 20085,\n",
       " 20086,\n",
       " 20087,\n",
       " 20088,\n",
       " 20089,\n",
       " 20090,\n",
       " 20091,\n",
       " 20092,\n",
       " 20093,\n",
       " 20094,\n",
       " 20095,\n",
       " 20096,\n",
       " 20097,\n",
       " 20098,\n",
       " 20099,\n",
       " 20100,\n",
       " 20101,\n",
       " 20102,\n",
       " 20103,\n",
       " 20104,\n",
       " 20105,\n",
       " 20106,\n",
       " 20107,\n",
       " 20108,\n",
       " 20109,\n",
       " 20110,\n",
       " 20111,\n",
       " 20112,\n",
       " 20113,\n",
       " 20114,\n",
       " 20115,\n",
       " 20116,\n",
       " 20117,\n",
       " 20118,\n",
       " 20119,\n",
       " 20120,\n",
       " 20121,\n",
       " 20122,\n",
       " 20123,\n",
       " 20124,\n",
       " 20125,\n",
       " 20126,\n",
       " 20127,\n",
       " 20128,\n",
       " 20129,\n",
       " 20130,\n",
       " 20131,\n",
       " 20132,\n",
       " 20133,\n",
       " 20134,\n",
       " 20135,\n",
       " 20136,\n",
       " 20137,\n",
       " 20138,\n",
       " 20139,\n",
       " 20140,\n",
       " 20141,\n",
       " 20142,\n",
       " 20143,\n",
       " 20144,\n",
       " 20145,\n",
       " 20146,\n",
       " 20147,\n",
       " 20148,\n",
       " 20149,\n",
       " 20150,\n",
       " 20151,\n",
       " 20152,\n",
       " 20153,\n",
       " 20154,\n",
       " 20155,\n",
       " 20156,\n",
       " 20157,\n",
       " 20158,\n",
       " 20159,\n",
       " 20160,\n",
       " 20161,\n",
       " 20162,\n",
       " 20163,\n",
       " 20164,\n",
       " 20165,\n",
       " 20166,\n",
       " 20167,\n",
       " 20168,\n",
       " 20169,\n",
       " 20170,\n",
       " 20171,\n",
       " 20172,\n",
       " 20173,\n",
       " 20174,\n",
       " 20175,\n",
       " 20176,\n",
       " 20177,\n",
       " 20178,\n",
       " 20179,\n",
       " 20180,\n",
       " 20181,\n",
       " 20182,\n",
       " 20183,\n",
       " 20184,\n",
       " 20185,\n",
       " 20186,\n",
       " 20187,\n",
       " 20188,\n",
       " 20189,\n",
       " 20190,\n",
       " 20191,\n",
       " 20192,\n",
       " 20193,\n",
       " 20194,\n",
       " 20195,\n",
       " 20196,\n",
       " 20197,\n",
       " 20198,\n",
       " 20199,\n",
       " 20200,\n",
       " 20201,\n",
       " 20202,\n",
       " 20203,\n",
       " 20204,\n",
       " 20205,\n",
       " 20206,\n",
       " 20207,\n",
       " 20208,\n",
       " 20209,\n",
       " 20210,\n",
       " 20211,\n",
       " 20212,\n",
       " 20213,\n",
       " 20214,\n",
       " 20215,\n",
       " 20216,\n",
       " 20217,\n",
       " 20218,\n",
       " 20219,\n",
       " 20220,\n",
       " 20221,\n",
       " 20222,\n",
       " 20223,\n",
       " 20224,\n",
       " 20225,\n",
       " 20226,\n",
       " 20227,\n",
       " 20228,\n",
       " 20229,\n",
       " 20230,\n",
       " 20231,\n",
       " 20232,\n",
       " 20233,\n",
       " 20234,\n",
       " 20235,\n",
       " 20236,\n",
       " 20237,\n",
       " 20238,\n",
       " 20239,\n",
       " 20240,\n",
       " 20241,\n",
       " 20242,\n",
       " 20243,\n",
       " 20244,\n",
       " 20245,\n",
       " 20246,\n",
       " 20247,\n",
       " 20248,\n",
       " 20249,\n",
       " 20250,\n",
       " 20251,\n",
       " 20252,\n",
       " 20253,\n",
       " 20254,\n",
       " 20255,\n",
       " 20256,\n",
       " 20257,\n",
       " 20258,\n",
       " 20259,\n",
       " 20260,\n",
       " 20261,\n",
       " 20262,\n",
       " 20263,\n",
       " 20264,\n",
       " 20265,\n",
       " 20266,\n",
       " 20267,\n",
       " 20268,\n",
       " 20269,\n",
       " 20270,\n",
       " 20271,\n",
       " 20272,\n",
       " 20273,\n",
       " 20274,\n",
       " 20275,\n",
       " 20276,\n",
       " 20277,\n",
       " 20278,\n",
       " 20279,\n",
       " 20280,\n",
       " 20281,\n",
       " 20282,\n",
       " 20283,\n",
       " 20284,\n",
       " 20285,\n",
       " 20286,\n",
       " 20287,\n",
       " 20288,\n",
       " 20289,\n",
       " 20290,\n",
       " 20291,\n",
       " 20292,\n",
       " 20293,\n",
       " 20294,\n",
       " 20295,\n",
       " 20296,\n",
       " 20297,\n",
       " 20298,\n",
       " 20299,\n",
       " 20300,\n",
       " 20301,\n",
       " 20302,\n",
       " 20303,\n",
       " 20304,\n",
       " 20305,\n",
       " 20306,\n",
       " 20307,\n",
       " 20308,\n",
       " 20309,\n",
       " 20310,\n",
       " 20311,\n",
       " 20312,\n",
       " 20313,\n",
       " 20314,\n",
       " 20315,\n",
       " 20316,\n",
       " 20317,\n",
       " 20318,\n",
       " 20319,\n",
       " 20320,\n",
       " 20321,\n",
       " 20322,\n",
       " 20323,\n",
       " 20324,\n",
       " 20325,\n",
       " 20326,\n",
       " 20327,\n",
       " 20328,\n",
       " 20329,\n",
       " 20330,\n",
       " 20331,\n",
       " 20332,\n",
       " 20333,\n",
       " 20334,\n",
       " 20335,\n",
       " 20336,\n",
       " 20337,\n",
       " 20338,\n",
       " 20339,\n",
       " 20340,\n",
       " 20341,\n",
       " 20342,\n",
       " 20343,\n",
       " 20344,\n",
       " 20345,\n",
       " 20346,\n",
       " 20347,\n",
       " 20348,\n",
       " 20349,\n",
       " 20350,\n",
       " 20351,\n",
       " 20352,\n",
       " 20353,\n",
       " 20354,\n",
       " 20355,\n",
       " 20356,\n",
       " 20357,\n",
       " 20358,\n",
       " 20359,\n",
       " 20360,\n",
       " 20361,\n",
       " 20362,\n",
       " 20363,\n",
       " 20364,\n",
       " 20365,\n",
       " 20366,\n",
       " 20367,\n",
       " 20368,\n",
       " 20369,\n",
       " 20370,\n",
       " 20371,\n",
       " 20372,\n",
       " 20373,\n",
       " 20374,\n",
       " 20375,\n",
       " 20376,\n",
       " 20377,\n",
       " 20378,\n",
       " 20379,\n",
       " 20380,\n",
       " 20381,\n",
       " 20382,\n",
       " 20383,\n",
       " 20384,\n",
       " 20385,\n",
       " 20386,\n",
       " 20387,\n",
       " 20388,\n",
       " 20389,\n",
       " 20390,\n",
       " 20391,\n",
       " 20392,\n",
       " 20393,\n",
       " 20394,\n",
       " 20395,\n",
       " 20396,\n",
       " 20397,\n",
       " 20398,\n",
       " 20399,\n",
       " 20400,\n",
       " 20401,\n",
       " 20402,\n",
       " 20403,\n",
       " 20404,\n",
       " 20405,\n",
       " 20406,\n",
       " 20407,\n",
       " 20408,\n",
       " 20409,\n",
       " 20410,\n",
       " 20411,\n",
       " 20412,\n",
       " 20413,\n",
       " 20414,\n",
       " 20415,\n",
       " 20416,\n",
       " 20417,\n",
       " 20418,\n",
       " 20419,\n",
       " 20420,\n",
       " 20421,\n",
       " 20422,\n",
       " 20423,\n",
       " 20424,\n",
       " 20425,\n",
       " 20426,\n",
       " 20427,\n",
       " 20428,\n",
       " 20429,\n",
       " 20430,\n",
       " 20431,\n",
       " 20432,\n",
       " 20433,\n",
       " 20434,\n",
       " 20435,\n",
       " 20436,\n",
       " 20437,\n",
       " 20438,\n",
       " 20439,\n",
       " 20440,\n",
       " 20441,\n",
       " 20442,\n",
       " 20443,\n",
       " 20444,\n",
       " 20445,\n",
       " 20446,\n",
       " 20447,\n",
       " 20448,\n",
       " 20449,\n",
       " 20450,\n",
       " 20451,\n",
       " 20452,\n",
       " 20453,\n",
       " 20454,\n",
       " 20455,\n",
       " 20456,\n",
       " 20457,\n",
       " 20458,\n",
       " 20459,\n",
       " 20460,\n",
       " 20461,\n",
       " 20462,\n",
       " 20463,\n",
       " 20464,\n",
       " 20465,\n",
       " 20466,\n",
       " 20467,\n",
       " 20468,\n",
       " 20469,\n",
       " 20470,\n",
       " 20471,\n",
       " 20472,\n",
       " 20473,\n",
       " 20474,\n",
       " 20475,\n",
       " 20476,\n",
       " 20477,\n",
       " 20478,\n",
       " 20479,\n",
       " 20480,\n",
       " 20481,\n",
       " 20482,\n",
       " 20483,\n",
       " 20484,\n",
       " 20485,\n",
       " 20486,\n",
       " 20487,\n",
       " 20488,\n",
       " 20489,\n",
       " 20490,\n",
       " 20491,\n",
       " 20492,\n",
       " 20493,\n",
       " 20494,\n",
       " 20495,\n",
       " 20496,\n",
       " 20497,\n",
       " 20498,\n",
       " 20499,\n",
       " 20500,\n",
       " 20501,\n",
       " 20502,\n",
       " 20503,\n",
       " 20504,\n",
       " 20505,\n",
       " 20506,\n",
       " 20507,\n",
       " 20508,\n",
       " 20509,\n",
       " 20510,\n",
       " 20511,\n",
       " 20512,\n",
       " 20513,\n",
       " 20514,\n",
       " 20515,\n",
       " 20516,\n",
       " 20517,\n",
       " 20518,\n",
       " 20519,\n",
       " 20520,\n",
       " 20521,\n",
       " 20522,\n",
       " 20523,\n",
       " 20524,\n",
       " 20525,\n",
       " 20526,\n",
       " 20527,\n",
       " 20528,\n",
       " 20529,\n",
       " 20530,\n",
       " 20531,\n",
       " 20532,\n",
       " 20533,\n",
       " 20534,\n",
       " 20535,\n",
       " 20536,\n",
       " 20537,\n",
       " 20538,\n",
       " 20539,\n",
       " 20540,\n",
       " 20541,\n",
       " 20542,\n",
       " 20543,\n",
       " 20544,\n",
       " 20545,\n",
       " 20546,\n",
       " 20547,\n",
       " 20548,\n",
       " 20549,\n",
       " 20550,\n",
       " 20551,\n",
       " 20552,\n",
       " 20553,\n",
       " 20554,\n",
       " 20555,\n",
       " 20556,\n",
       " 20557,\n",
       " 20558,\n",
       " 20559,\n",
       " 20560,\n",
       " 20561,\n",
       " 20562,\n",
       " 20563,\n",
       " 20564,\n",
       " 20565,\n",
       " 20566,\n",
       " 20567,\n",
       " 20568,\n",
       " 20569,\n",
       " 20570,\n",
       " 20571,\n",
       " 20572,\n",
       " 20573,\n",
       " 20574,\n",
       " 20575,\n",
       " 20576,\n",
       " 20577,\n",
       " 20578,\n",
       " 20579,\n",
       " 20580,\n",
       " 20581,\n",
       " 20582,\n",
       " 20583,\n",
       " 20584,\n",
       " 20585,\n",
       " 20586,\n",
       " 20587,\n",
       " 20588,\n",
       " 20589,\n",
       " 20590,\n",
       " 20591,\n",
       " 20592,\n",
       " 20593,\n",
       " 20594,\n",
       " 20595,\n",
       " 20596,\n",
       " 20597,\n",
       " 20598,\n",
       " 20599,\n",
       " 20600,\n",
       " 20601,\n",
       " 20602,\n",
       " 20603,\n",
       " 20604,\n",
       " 20605,\n",
       " 20606,\n",
       " 20607,\n",
       " 20608,\n",
       " 20609,\n",
       " 20610,\n",
       " 20611,\n",
       " 20612,\n",
       " 20613,\n",
       " 20614,\n",
       " 20615,\n",
       " 20616,\n",
       " 20617,\n",
       " 20618,\n",
       " 20619,\n",
       " 20620,\n",
       " 20621,\n",
       " 20622,\n",
       " 20623,\n",
       " 20624,\n",
       " 20625,\n",
       " 20626,\n",
       " 20627,\n",
       " 20628,\n",
       " 20629,\n",
       " 20630,\n",
       " 20631,\n",
       " 20632,\n",
       " 20633,\n",
       " 20634,\n",
       " 20635,\n",
       " 20636,\n",
       " 20637,\n",
       " 20638,\n",
       " 20639,\n",
       " 20640,\n",
       " 20641,\n",
       " 20642,\n",
       " 20643,\n",
       " 20644,\n",
       " 20645,\n",
       " 20646,\n",
       " 20647,\n",
       " 20648,\n",
       " 20649,\n",
       " 20650,\n",
       " 20651,\n",
       " 20652,\n",
       " 20653,\n",
       " 20654,\n",
       " 20655,\n",
       " 20656,\n",
       " 20657,\n",
       " 20658,\n",
       " 20659,\n",
       " 20660,\n",
       " 20661,\n",
       " 20662,\n",
       " 20663,\n",
       " 20664,\n",
       " 20665,\n",
       " 20666,\n",
       " 20667,\n",
       " 20668,\n",
       " 20669,\n",
       " 20670,\n",
       " 20671,\n",
       " 20672,\n",
       " 20673,\n",
       " 20674,\n",
       " 20675,\n",
       " 20676,\n",
       " 20677,\n",
       " 20678,\n",
       " 20679,\n",
       " 20680,\n",
       " 20681,\n",
       " 20682,\n",
       " 20683,\n",
       " 20684,\n",
       " 20685,\n",
       " 20686,\n",
       " 20687,\n",
       " 20688,\n",
       " 20689,\n",
       " 20690,\n",
       " 20691,\n",
       " 20692,\n",
       " 20693,\n",
       " 20694,\n",
       " 20695,\n",
       " 20696,\n",
       " 20697,\n",
       " 20698,\n",
       " 20699,\n",
       " 20700,\n",
       " 20701,\n",
       " 20702,\n",
       " 20703,\n",
       " 20704,\n",
       " 20705,\n",
       " 20706,\n",
       " 20707,\n",
       " 20708,\n",
       " 20709,\n",
       " 20710,\n",
       " 20711,\n",
       " 20712,\n",
       " 20713,\n",
       " 20714,\n",
       " 20715,\n",
       " 20716,\n",
       " 20717,\n",
       " 20718,\n",
       " 20719,\n",
       " 20720,\n",
       " 20721,\n",
       " 20722,\n",
       " 20723,\n",
       " 20724,\n",
       " 20725,\n",
       " 20726,\n",
       " 20727,\n",
       " 20728,\n",
       " 20729,\n",
       " 20730,\n",
       " 20731,\n",
       " 20732,\n",
       " 20733,\n",
       " 20734,\n",
       " 20735,\n",
       " 20736,\n",
       " 20737,\n",
       " 20738,\n",
       " 20739,\n",
       " 20740,\n",
       " 20741,\n",
       " 20742,\n",
       " 20743,\n",
       " 20744,\n",
       " 20745,\n",
       " 20746,\n",
       " 20747,\n",
       " 20748,\n",
       " 20749,\n",
       " 20750,\n",
       " 20751,\n",
       " 20752,\n",
       " 20753,\n",
       " 20754,\n",
       " 20755,\n",
       " 20756,\n",
       " 20757,\n",
       " 20758,\n",
       " 20759,\n",
       " 20760,\n",
       " 20761,\n",
       " 20762,\n",
       " 20763,\n",
       " 20764,\n",
       " 20765,\n",
       " 20766,\n",
       " 20767,\n",
       " 20768,\n",
       " 20769,\n",
       " 20770,\n",
       " 20771,\n",
       " 20772,\n",
       " 20773,\n",
       " 20774,\n",
       " 20775,\n",
       " 20776,\n",
       " 20777,\n",
       " 20778,\n",
       " 20779,\n",
       " 20780,\n",
       " 20781,\n",
       " 20782,\n",
       " 20783,\n",
       " 20784,\n",
       " 20785,\n",
       " 20786,\n",
       " 20787,\n",
       " 20788,\n",
       " 20789,\n",
       " 20790,\n",
       " 20791,\n",
       " 20792,\n",
       " 20793,\n",
       " 20794,\n",
       " 20795,\n",
       " 20796,\n",
       " 20797,\n",
       " 20798,\n",
       " 20799,\n",
       " 20800,\n",
       " 20801,\n",
       " 20802,\n",
       " 20803,\n",
       " 20804,\n",
       " 20805,\n",
       " 20806,\n",
       " 20807,\n",
       " 20808,\n",
       " 20809,\n",
       " 20810,\n",
       " 20811,\n",
       " 20812,\n",
       " 20813,\n",
       " 20814,\n",
       " 20815,\n",
       " 20816,\n",
       " 20817,\n",
       " 20818,\n",
       " 20819,\n",
       " 20820,\n",
       " 20821,\n",
       " 20822,\n",
       " 20823,\n",
       " 20824,\n",
       " 20825,\n",
       " 20826,\n",
       " 20827,\n",
       " 20828,\n",
       " 20829,\n",
       " 20830,\n",
       " 20831,\n",
       " 20832,\n",
       " 20833,\n",
       " 20834,\n",
       " 20835,\n",
       " 20836,\n",
       " 20837,\n",
       " 20838,\n",
       " 20839,\n",
       " 20840,\n",
       " 20841,\n",
       " 20842,\n",
       " 20843,\n",
       " 20844,\n",
       " 20845,\n",
       " 20846,\n",
       " 20847,\n",
       " 20848,\n",
       " 20849,\n",
       " 20850,\n",
       " 20851,\n",
       " 20852,\n",
       " 20853,\n",
       " 20854,\n",
       " 20855,\n",
       " 20856,\n",
       " 20857,\n",
       " 20858,\n",
       " 20859,\n",
       " 20860,\n",
       " 20861,\n",
       " 20862,\n",
       " 20863,\n",
       " 20864,\n",
       " 20865,\n",
       " 20866,\n",
       " 20867,\n",
       " 20868,\n",
       " 20869,\n",
       " 20870,\n",
       " 20871,\n",
       " 20872,\n",
       " 20873,\n",
       " 20874,\n",
       " 20875,\n",
       " 20876,\n",
       " 20877,\n",
       " 20878,\n",
       " 20879,\n",
       " 20880,\n",
       " 20881,\n",
       " 20882,\n",
       " 20883,\n",
       " 20884,\n",
       " 20885,\n",
       " 20886,\n",
       " 20887,\n",
       " 20888,\n",
       " 20889,\n",
       " 20890,\n",
       " 20891,\n",
       " 20892,\n",
       " 20893,\n",
       " 20894,\n",
       " 20895,\n",
       " 20896,\n",
       " 20897,\n",
       " 20898,\n",
       " 20899,\n",
       " 20900,\n",
       " 20901,\n",
       " 20902,\n",
       " 20903,\n",
       " 20904,\n",
       " 20905,\n",
       " 20906,\n",
       " 20907,\n",
       " 20908,\n",
       " 20909,\n",
       " 20910,\n",
       " 20911,\n",
       " 20912,\n",
       " 20913,\n",
       " 20914,\n",
       " 20915,\n",
       " 20916,\n",
       " 20917,\n",
       " 20918,\n",
       " 20919,\n",
       " 20920,\n",
       " 20921,\n",
       " 20922,\n",
       " 20923,\n",
       " 20924,\n",
       " 20925,\n",
       " 20926,\n",
       " 20927,\n",
       " 20928,\n",
       " 20929,\n",
       " 20930,\n",
       " 20931,\n",
       " 20932,\n",
       " 20933,\n",
       " 20934,\n",
       " 20935,\n",
       " 20936,\n",
       " 20937,\n",
       " 20938,\n",
       " 20939,\n",
       " 20940,\n",
       " 20941,\n",
       " 20942,\n",
       " 20943,\n",
       " 20944,\n",
       " 20945,\n",
       " 20946,\n",
       " 20947,\n",
       " 20948,\n",
       " 20949,\n",
       " 20950,\n",
       " 20951,\n",
       " 20952,\n",
       " 20953,\n",
       " 20954,\n",
       " 20955,\n",
       " 20956,\n",
       " 20957,\n",
       " 20958,\n",
       " 20959,\n",
       " 20960,\n",
       " 20961,\n",
       " 20962,\n",
       " 20963,\n",
       " 20964,\n",
       " 20965,\n",
       " 20966,\n",
       " 20967,\n",
       " 20968,\n",
       " 20969,\n",
       " 20970,\n",
       " 20971,\n",
       " 20972,\n",
       " 20973,\n",
       " 20974,\n",
       " 20975,\n",
       " 20976,\n",
       " 20977,\n",
       " 20978,\n",
       " 20979,\n",
       " 20980,\n",
       " 20981,\n",
       " 20982,\n",
       " 20983,\n",
       " 20984,\n",
       " 20985,\n",
       " 20986,\n",
       " 20987,\n",
       " 20988,\n",
       " 20989,\n",
       " 20990,\n",
       " 20991,\n",
       " 20992,\n",
       " 20993,\n",
       " 20994,\n",
       " 20995,\n",
       " 20996,\n",
       " 20997,\n",
       " 20998,\n",
       " 20999,\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "provider.getDataFiles(f'{configGlobal.data.basepath}/split/val.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = Namespace(config='configs/KITTITrackletsCarsHard.json', \n",
    "                  eval_epoch='28', \n",
    "                  its=30, \n",
    "                  operation='eval_only', \n",
    "                  refineICP=False, \n",
    "                  refineICPmethod='p2p', \n",
    "                  use_old_results=False)\n",
    "load_config(FLAGS.config)\n",
    "\n",
    "# temp fix\n",
    "TRAIN_INDICES = provider.getDataFiles(f'{configGlobal.data.basepath}/split/train.txt')\n",
    "VAL_INDICES = provider.getDataFiles(f'{configGlobal.data.basepath}/split/val.txt')\n",
    "configGlobal.data.__dict__[\"ntrain\"] = len(TRAIN_INDICES)\n",
    "configGlobal.data.__dict__[\"nval\"] = len(VAL_INDICES)\n",
    "\n",
    "cfg = configGlobal\n",
    "\n",
    "MODEL = MODEL_tp8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support function\n",
    "def get_bn_decay(batch):\n",
    "    num_batches_per_epoch = len(TRAIN_INDICES) // cfg.training.batch_size\n",
    "\n",
    "    assert cfg.training.bn_extension.mode == 'decay'\n",
    "\n",
    "    bn_decay_step = cfg.training.bn_extension.step\n",
    "    if cfg.training.bn_extension.per == 'step':\n",
    "        pass\n",
    "    elif cfg.training.bn_extension.per == 'epoch':\n",
    "        bn_decay_step *= cfg.training.batch_size * num_batches_per_epoch\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "    bn_momentum = tf.train.exponential_decay(cfg.training.bn_extension.init, batch * cfg.training.batch_size, bn_decay_step, cfg.training.bn_extension.rate, staircase=True)\n",
    "    bn_decay = tf.minimum(cfg.training.bn_extension.clip, 1 - bn_momentum)\n",
    "    return bn_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/usuario/project/align3d/utils/tf_util.py:574: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/usuario/project/align3d/models/tp8.py:215: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /home/usuario/project/align3d/models/tp8.py:205: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_learning_rate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-859ca5e56331>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Get training operator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hyperparameters/learning_rate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'momentum'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_learning_rate' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:' + str(cfg.gpu_index)):\n",
    "        pcs1, pcs2, translations, rel_angles, pc1centers, pc2centers, pc1angles, pc2angles = MODEL.placeholder_inputs(cfg.training.batch_size, cfg.model.num_points)\n",
    "        is_training_pl = tf.placeholder(tf.bool, shape=())\n",
    "\n",
    "        # Note the global_step=batch parameter to minimize.\n",
    "        # That tells the optimizer to helpfully increment the 'batch' parameter for you every time it trains.\n",
    "        batch = tf.Variable(0)\n",
    "        bn_decay = get_bn_decay(batch)\n",
    "        tf.summary.scalar('hyperparameters/bn_decay', bn_decay)\n",
    "\n",
    "        # Get model and loss\n",
    "        end_points = MODEL.get_model(pcs1, pcs2, is_training_pl, bn_decay=bn_decay)\n",
    "        loss = MODEL.get_loss(pcs1, pcs2, translations, rel_angles, pc1centers, pc2centers, pc1angles, pc2angles, end_points)\n",
    "        tf.summary.scalar('losses/loss', loss)\n",
    "\n",
    "        #  correct = tf.equal(tf.argmax(pred, 1), tf.to_int64(labels_pl))\n",
    "        #  accuracy = tf.reduce_sum(tf.cast(correct, tf.float32)) / float(cfg.training.batch_size)\n",
    "        #  tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "        # Get training operator\n",
    "        learning_rate = get_learning_rate(batch)\n",
    "        tf.summary.scalar('hyperparameters/learning_rate', learning_rate)\n",
    "        if cfg.training.optimizer.optimizer == 'momentum':\n",
    "            optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=cfg.training.optimizer.momentum)\n",
    "        elif cfg.training.optimizer.optimizer == 'adam':\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        else:\n",
    "            assert False, \"Invalid optimizer\"\n",
    "        train_op = optimizer.minimize(loss, global_step=batch)\n",
    "\n",
    "        # Add ops to save and restore all the variables.\n",
    "        saver = tf.train.Saver(max_to_keep=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_only_model_to_load=None\n",
    "eval_only=True\n",
    "eval_epoch=FLAGS.eval_epoch\n",
    "do_timings=False\n",
    "override_batch_size=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/usuario/project_data/trained/KITTITrackletsCarsHard/model-28\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-1b57468f21e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_old_results\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdo_timings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{model_to_load}/model-{eval_epoch}.index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{model_to_load}/model-{eval_epoch}.index'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{model_to_load}/model-{eval_epoch}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mstart_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/thesis/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1290\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1291\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m       \u001b[0;31m# There are three common conditions that might cause this error:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/thesis/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/thesis/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/thesis/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/thesis/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/thesis/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/thesis/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    with tf.device('/gpu:' + str(cfg.gpu_index)):\n",
    "        pcs1, pcs2, translations, rel_angles, pc1centers, pc2centers, pc1angles, pc2angles = MODEL.placeholder_inputs(cfg.training.batch_size, cfg.model.num_points)\n",
    "        is_training_pl = tf.placeholder(tf.bool, shape=())\n",
    "\n",
    "        # Note the global_step=batch parameter to minimize.\n",
    "        # That tells the optimizer to helpfully increment the 'batch' parameter for you every time it trains.\n",
    "        batch = tf.Variable(0)\n",
    "        bn_decay = get_bn_decay(batch)\n",
    "        tf.summary.scalar('hyperparameters/bn_decay', bn_decay)\n",
    "\n",
    "        # Get model and loss\n",
    "        end_points = MODEL.get_model(pcs1, pcs2, is_training_pl, bn_decay=bn_decay)\n",
    "        loss = MODEL.get_loss(pcs1, pcs2, translations, rel_angles, pc1centers, pc2centers, pc1angles, pc2angles, end_points)\n",
    "        tf.summary.scalar('losses/loss', loss)\n",
    "\n",
    "        #  correct = tf.equal(tf.argmax(pred, 1), tf.to_int64(labels_pl))\n",
    "        #  accuracy = tf.reduce_sum(tf.cast(correct, tf.float32)) / float(cfg.training.batch_size)\n",
    "        #  tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "        # Get training operator\n",
    "        #learning_rate = get_learning_rate(batch)\n",
    "        #tf.summary.scalar('hyperparameters/learning_rate', learning_rate)\n",
    "        #if cfg.training.optimizer.optimizer == 'momentum':\n",
    "        #    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=cfg.training.optimizer.momentum)\n",
    "        #elif cfg.training.optimizer.optimizer == 'adam':\n",
    "        #    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        #else:\n",
    "        #    assert False, \"Invalid optimizer\"\n",
    "        #train_op = optimizer.minimize(loss, global_step=batch)\n",
    "\n",
    "        # Add ops to save and restore all the variables.\n",
    "        saver = tf.train.Saver(max_to_keep=1000)\n",
    "    # Create a session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.allow_soft_placement = True\n",
    "    config.log_device_placement = False\n",
    "    sess = tf.Session(config=config)\n",
    "    merged = tf.summary.merge_all()\n",
    "    train_writer = tf.summary.FileWriter(os.path.join(cfg.logging.logdir, 'train'), sess.graph)\n",
    "    val_writer = tf.summary.FileWriter(os.path.join(cfg.logging.logdir, 'val'))\n",
    "    val_writer_180 = tf.summary.FileWriter(os.path.join(cfg.logging.logdir, 'val_180'))\n",
    "\n",
    "    # Init variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    # To fix the bug introduced in TF 0.12.1 as in\n",
    "    # http://stackoverflow.com/questions/41543774/invalidargumenterror-for-tensor-bool-tensorflow-0-12-1\n",
    "    # sess.run(init)\n",
    "    sess.run(init, {is_training_pl: True})\n",
    "    \n",
    "    ops = {'pcs1': pcs1, \n",
    "           'pcs2': pcs2, \n",
    "           'translations': translations, \n",
    "           'rel_angles': rel_angles, \n",
    "           'is_training_pl': is_training_pl, \n",
    "           'pred_translations': end_points['pred_translations'], \n",
    "           'pred_remaining_angle_logits': end_points['pred_remaining_angle_logits'], \n",
    "           'pc1centers': pc1centers, \n",
    "           'pc2centers': pc2centers, \n",
    "           'pc1angles': pc1angles, \n",
    "           'pc2angles': pc2angles, \n",
    "           'pred_s1_pc1centers': end_points['pred_s1_pc1centers'], \n",
    "           'pred_s1_pc2centers': end_points['pred_s1_pc2centers'], \n",
    "           'pred_s2_pc1centers': end_points['pred_s2_pc1centers'], \n",
    "           'pred_s2_pc2centers': end_points['pred_s2_pc2centers'], \n",
    "           'pred_pc1angle_logits': end_points['pred_pc1angle_logits'], \n",
    "           'pred_pc2angle_logits': end_points['pred_pc2angle_logits'], \n",
    "           'loss': loss, \n",
    "           #'train_op': train_op, \n",
    "           'merged': merged, \n",
    "           'step': batch}\n",
    "\n",
    "    \n",
    "    model_to_load = cfg.logging.logdir\n",
    "    if eval_only_model_to_load is not None:\n",
    "        model_to_load = eval_only_model_to_load\n",
    "    if not FLAGS.use_old_results and not do_timings:\n",
    "        assert os.path.isfile(f'{model_to_load}/model-{eval_epoch}.index'), f'{model_to_load}/model-{eval_epoch}.index'\n",
    "        saver.restore(sess, f'{model_to_load}/model-{eval_epoch}')\n",
    "    start_epoch = int(eval_epoch)\n",
    "\n",
    "    if eval_only_model_to_load is None:\n",
    "        num_batches_per_epoch = len(TRAIN_INDICES) // cfg.training.batch_size\n",
    "\n",
    "        if FLAGS.use_old_results or do_timings:\n",
    "            start_epoch = int(eval_epoch)\n",
    "        else:\n",
    "            restored_batch = sess.run(batch)\n",
    "            assert restored_batch % num_batches_per_epoch == 0\n",
    "            start_epoch = restored_batch // num_batches_per_epoch - 1\n",
    "            assert start_epoch == int(eval_epoch)\n",
    "    print(f'Evaluating at epoch {start_epoch}')\n",
    "    \n",
    "    epoch = 28\n",
    "    \n",
    "    is_training = False\n",
    "    batch_size = cfg.training.batch_size if override_batch_size is None else override_batch_size\n",
    "\n",
    "    val_idxs = VAL_INDICES\n",
    "    num_batches = int(np.ceil(len(val_idxs) / batch_size))\n",
    "    num_full_batches = int(np.floor(len(val_idxs) / batch_size))\n",
    "\n",
    "    loss_sum = 0\n",
    "    global_step = sess.run([ops['step']])[0]\n",
    "    #  step_in_epochs = epoch + 1\n",
    "    eval_dir = f'{cfg.logging.logdir}/val/eval{str(epoch).zfill(6)}'\n",
    "    base_eval_dir = eval_dir\n",
    "    if FLAGS.refineICP:\n",
    "        eval_dir = f'{eval_dir}/refined_{FLAGS.refineICPmethod}{\"_\"+FLAGS.its if FLAGS.its != 30 else \"\"}'\n",
    "\n",
    "    if os.path.isdir(eval_dir):\n",
    "        os.rename(eval_dir, f'{eval_dir}_backup_{int(time.time())}')\n",
    "\n",
    "    os.makedirs(eval_dir, exist_ok=True)\n",
    "\n",
    "    all_pred_translations = np.empty((len(val_idxs), 3), dtype=np.float32)\n",
    "    all_pred_angles = np.empty((len(val_idxs), 1), dtype=np.float32)\n",
    "\n",
    "    all_pred_s1_pc1centers = np.empty((len(val_idxs), 3), dtype=np.float32)\n",
    "    all_pred_s1_pc2centers = np.empty((len(val_idxs), 3), dtype=np.float32)\n",
    "    all_pred_s2_pc1centers = np.empty((len(val_idxs), 3), dtype=np.float32)\n",
    "    all_pred_s2_pc2centers = np.empty((len(val_idxs), 3), dtype=np.float32)\n",
    "    all_pred_s2_pc1angles = np.empty((len(val_idxs), 1), dtype=np.float32)\n",
    "    all_pred_s2_pc2angles = np.empty((len(val_idxs), 1), dtype=np.float32)\n",
    "\n",
    "    all_gt_translations = np.empty((len(val_idxs), 3), dtype=np.float32)\n",
    "    all_gt_angles = np.empty((len(val_idxs), 1), dtype=np.float32)\n",
    "    all_gt_pc1centers = np.empty((len(val_idxs), 3), dtype=np.float32)\n",
    "    \n",
    "    cumulated_times = 0.\n",
    "    for batch_idx in range(num_batches):\n",
    "        print('----- batch ' + str(batch_idx) + ' -----')\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min((batch_idx + 1) * batch_size, len(val_idxs))\n",
    "\n",
    "        pcs1, pcs2, translations, rel_angles, pc1centers, pc2centers, pc1angles, pc2angles = provider.load_batch(val_idxs[start_idx:end_idx], override_batch_size=override_batch_size)\n",
    "\n",
    "        feed_dict = {\n",
    "            ops['pcs1']: pcs1,\n",
    "            ops['pcs2']: pcs2,\n",
    "            ops['translations']: translations,\n",
    "            ops['rel_angles']: rel_angles,\n",
    "            ops['is_training_pl']: is_training,\n",
    "            ops['pc1centers']: pc1centers,\n",
    "            ops['pc2centers']: pc2centers,\n",
    "            ops['pc1angles']: pc1angles,\n",
    "            ops['pc2angles']: pc2angles,\n",
    "        }\n",
    "        start = time.time()\n",
    "        summary, loss_val, pred_translations, pred_pc1angle_logits, pred_pc2angle_logits, pred_remaining_angle_logits, pred_s1_pc1centers, pred_s1_pc2centers, pred_s2_pc1centers, pred_s2_pc2centers = sess.run([ops['merged'], ops['loss'], ops['pred_translations'], ops['pred_pc1angle_logits'], ops['pred_pc2angle_logits'], ops['pred_remaining_angle_logits'], ops['pred_s1_pc1centers'], ops['pred_s1_pc2centers'], ops['pred_s2_pc1centers'], ops['pred_s2_pc2centers']], feed_dict=feed_dict)\n",
    "        cumulated_times += time.time() - start\n",
    "        #  val_writer.add_summary(summary, step)\n",
    "        actual_batch_size = end_idx - start_idx\n",
    "        pred_translations = pred_translations[:actual_batch_size]\n",
    "        pred_angles_pc1 = MODEL.classLogits2angle(pred_pc1angle_logits[:actual_batch_size])\n",
    "        pred_angles_pc2 = MODEL.classLogits2angle(pred_pc2angle_logits[:actual_batch_size])\n",
    "        pred_angles_remaining = MODEL.classLogits2angle(pred_remaining_angle_logits[:actual_batch_size])\n",
    "        pred_angles = pred_angles_pc2 - pred_angles_pc1 + pred_angles_remaining\n",
    "\n",
    "        if actual_batch_size == batch_size:  # last batch is not counted\n",
    "            loss_sum += loss_val\n",
    "        \n",
    "        # Some parameters\n",
    "        mean_per_transform_loss = loss_sum / num_full_batches if num_full_batches > 0 else 0.\n",
    "        mean_execution_time = cumulated_times / float(len(val_idxs))\n",
    "        \n",
    "        print(f\"{loss_sum}\")\n",
    "        \n",
    "        # Store result to big array\n",
    "        for idx in range(actual_batch_size):\n",
    "            global_idx = start_idx + idx\n",
    "\n",
    "            all_pred_translations[global_idx] = pred_translations[idx]\n",
    "            all_pred_angles[global_idx] = pred_angles[idx]\n",
    "\n",
    "            all_pred_s1_pc1centers[global_idx] = pred_s1_pc1centers[idx]\n",
    "            all_pred_s1_pc2centers[global_idx] = pred_s1_pc2centers[idx]\n",
    "            all_pred_s2_pc1centers[global_idx] = pred_s2_pc1centers[idx]\n",
    "            all_pred_s2_pc2centers[global_idx] = pred_s2_pc2centers[idx]\n",
    "\n",
    "            all_pred_s2_pc1angles[global_idx] = pred_angles_pc1[idx]\n",
    "            all_pred_s2_pc2angles[global_idx] = pred_angles_pc2[idx]\n",
    "\n",
    "            all_gt_translations[global_idx] = translations[idx]\n",
    "            all_gt_angles[global_idx] = rel_angles[idx]\n",
    "            all_gt_pc1centers[global_idx] = pc1centers[idx]\n",
    "        \n",
    "        print(\"Results stored\")\n",
    "        \n",
    "    eval_dict = evaluation.evaluate(cfg, val_idxs, all_pred_translations, all_pred_angles, \n",
    "                                    all_gt_translations, all_gt_angles, all_pred_s2_pc1centers, \n",
    "                                    all_gt_pc1centers, eval_dir=eval_dir, \n",
    "                                    accept_inverted_angle=True, \n",
    "                                    mean_time=mean_execution_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_angles_pc1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_translations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_one_epoch(sess, ops, val_writer, val_writer_180, epoch, eval_only=eval_only, do_timings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_one_epoch(sess, ops, val_writer, val_writer_180, epoch, eval_only, do_timings, override_batch_size=None):\n",
    "    \"\"\" ops: dict mapping from string to tf ops \"\"\"\n",
    "\n",
    "    is_training = False\n",
    "    batch_size = cfg.training.batch_size if override_batch_size is None else override_batch_size\n",
    "\n",
    "    val_idxs = VAL_INDICES\n",
    "    num_batches = int(np.ceil(len(val_idxs) / batch_size))\n",
    "    num_full_batches = int(np.floor(len(val_idxs) / batch_size))\n",
    "\n",
    "    loss_sum = 0\n",
    "    global_step = sess.run([ops['step']])[0]\n",
    "    #  step_in_epochs = epoch + 1\n",
    "    eval_dir = f'{cfg.logging.logdir}/val/eval{str(epoch).zfill(6)}'\n",
    "    base_eval_dir = eval_dir\n",
    "    if FLAGS.refineICP:\n",
    "        eval_dir = f'{eval_dir}/refined_{FLAGS.refineICPmethod}{\"_\"+FLAGS.its if FLAGS.its != 30 else \"\"}'\n",
    "\n",
    "    if os.path.isdir(eval_dir):\n",
    "        os.rename(eval_dir, f'{eval_dir}_backup_{int(time.time())}')\n",
    "\n",
    "    os.makedirs(eval_dir, exist_ok=True)\n",
    "\n",
    "    all_pred_translations = np.empty((len(val_idxs), 3), dtype=np.float32)\n",
    "    all_pred_angles = np.empty((len(val_idxs), 1), dtype=np.float32)\n",
    "\n",
    "    all_pred_s1_pc1centers = np.empty((len(val_idxs), 3), dtype=np.float32)\n",
    "    all_pred_s1_pc2centers = np.empty((len(val_idxs), 3), dtype=np.float32)\n",
    "    all_pred_s2_pc1centers = np.empty((len(val_idxs), 3), dtype=np.float32)\n",
    "    all_pred_s2_pc2centers = np.empty((len(val_idxs), 3), dtype=np.float32)\n",
    "    all_pred_s2_pc1angles = np.empty((len(val_idxs), 1), dtype=np.float32)\n",
    "    all_pred_s2_pc2angles = np.empty((len(val_idxs), 1), dtype=np.float32)\n",
    "\n",
    "    all_gt_translations = np.empty((len(val_idxs), 3), dtype=np.float32)\n",
    "    all_gt_angles = np.empty((len(val_idxs), 1), dtype=np.float32)\n",
    "    all_gt_pc1centers = np.empty((len(val_idxs), 3), dtype=np.float32)\n",
    "\n",
    "    if FLAGS.use_old_results:\n",
    "        all_pred_translations = np.load(f'{base_eval_dir}/pred_translations.npy')\n",
    "        all_pred_angles = np.load(f'{base_eval_dir}/pred_angles.npy')\n",
    "        all_pred_s2_pc1centers = np.load(f'{base_eval_dir}/pred_s2_pc1centers.npy')\n",
    "\n",
    "    cumulated_times = 0.\n",
    "    for batch_idx in tqdm(range(num_batches), desc='val'):\n",
    "        #  logger.info('----- batch ' + str(batch_idx) + ' -----')\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min((batch_idx + 1) * batch_size, len(val_idxs))\n",
    "\n",
    "        pcs1, pcs2, translations, rel_angles, pc1centers, pc2centers, pc1angles, pc2angles = provider.load_batch(val_idxs[start_idx:end_idx], override_batch_size=override_batch_size)\n",
    "\n",
    "        feed_dict = {\n",
    "            ops['pcs1']: pcs1,\n",
    "            ops['pcs2']: pcs2,\n",
    "            ops['translations']: translations,\n",
    "            ops['rel_angles']: rel_angles,\n",
    "            ops['is_training_pl']: is_training,\n",
    "            ops['pc1centers']: pc1centers,\n",
    "            ops['pc2centers']: pc2centers,\n",
    "            ops['pc1angles']: pc1angles,\n",
    "            ops['pc2angles']: pc2angles,\n",
    "        }\n",
    "        start = time.time()\n",
    "        summary, loss_val, pred_translations, pred_pc1angle_logits, pred_pc2angle_logits, pred_remaining_angle_logits, pred_s1_pc1centers, pred_s1_pc2centers, pred_s2_pc1centers, pred_s2_pc2centers = sess.run([ops['merged'], ops['loss'], ops['pred_translations'], ops['pred_pc1angle_logits'], ops['pred_pc2angle_logits'], ops['pred_remaining_angle_logits'], ops['pred_s1_pc1centers'], ops['pred_s1_pc2centers'], ops['pred_s2_pc1centers'], ops['pred_s2_pc2centers']], feed_dict=feed_dict)\n",
    "        cumulated_times += time.time() - start\n",
    "        #  val_writer.add_summary(summary, step)\n",
    "        actual_batch_size = end_idx - start_idx\n",
    "        pred_translations = pred_translations[:actual_batch_size]\n",
    "        pred_angles_pc1 = MODEL.classLogits2angle(pred_pc1angle_logits[:actual_batch_size])\n",
    "        pred_angles_pc2 = MODEL.classLogits2angle(pred_pc2angle_logits[:actual_batch_size])\n",
    "        pred_angles_remaining = MODEL.classLogits2angle(pred_remaining_angle_logits[:actual_batch_size])\n",
    "        pred_angles = pred_angles_pc2 - pred_angles_pc1 + pred_angles_remaining\n",
    "\n",
    "        if actual_batch_size == batch_size:  # last batch is not counted\n",
    "            loss_sum += loss_val\n",
    "\n",
    "        for idx in range(actual_batch_size):\n",
    "            global_idx = start_idx + idx\n",
    "            if eval_only and FLAGS.refineICP:\n",
    "                if FLAGS.use_old_results:\n",
    "                    init = get_mat_angle(all_pred_translations[global_idx], all_pred_angles[global_idx], rotation_center=all_pred_s2_pc1centers[global_idx])\n",
    "                else:\n",
    "                    init = get_mat_angle(pred_translations[idx], pred_angles[idx], rotation_center=pred_s2_pc1centers[idx])\n",
    "                # Careful: Pass full point cloud, not subsampled one\n",
    "                refined_pred_transform, refined_pred_center, time_elapsed = icp.icp_p2point(val_idxs[global_idx], cfg, with_constraint=True, radius=0.1, init=init, its=int(FLAGS.its))\n",
    "                cumulated_times += time_elapsed\n",
    "                #  if refined_pred_transform[2, 2] == -1:\n",
    "                #  refined_pred_transform = init\n",
    "                #  Overwrite predicted translation and angle in place, then update all_pred_... later\n",
    "                pred_translations[idx] = refined_pred_transform[:3, 3]\n",
    "                rotation_mat = refined_pred_transform[:3, :3]\n",
    "                rot_vec = Rotation.from_dcm(rotation_mat).as_euler('xyz')\n",
    "                #  if global_idx == 47:\n",
    "                #  print(global_idx, '   ', evaluation.eval_angle(rot_vec[2], all_pred_angles[global_idx], True)[0])\n",
    "                #  print(refined_pred_transform)\n",
    "                #  print(init)\n",
    "                #  print(rot_vec)\n",
    "                pred_angles[idx] = rot_vec[2]\n",
    "                #  The transformation ICP outputs is in world space, thus with a rotation around 0,0,0. Store this so that a comparable translation and rotation can be computed later\n",
    "                pred_s2_pc1centers[idx] = [0., 0, 0]\n",
    "\n",
    "            all_pred_translations[global_idx] = pred_translations[idx]\n",
    "            all_pred_angles[global_idx] = pred_angles[idx]\n",
    "\n",
    "            all_pred_s1_pc1centers[global_idx] = pred_s1_pc1centers[idx]\n",
    "            all_pred_s1_pc2centers[global_idx] = pred_s1_pc2centers[idx]\n",
    "            all_pred_s2_pc1centers[global_idx] = pred_s2_pc1centers[idx]\n",
    "            all_pred_s2_pc2centers[global_idx] = pred_s2_pc2centers[idx]\n",
    "\n",
    "            all_pred_s2_pc1angles[global_idx] = pred_angles_pc1[idx]\n",
    "            all_pred_s2_pc2angles[global_idx] = pred_angles_pc2[idx]\n",
    "\n",
    "            all_gt_translations[global_idx] = translations[idx]\n",
    "            all_gt_angles[global_idx] = rel_angles[idx]\n",
    "            all_gt_pc1centers[global_idx] = pc1centers[idx]\n",
    "\n",
    "    mean_per_transform_loss = loss_sum / num_full_batches if num_full_batches > 0 else 0.\n",
    "    mean_execution_time = cumulated_times / float(len(val_idxs))\n",
    "\n",
    "    if do_timings:\n",
    "        print(f'Timing bs={override_batch_size}: {mean_execution_time}')\n",
    "    elif cfg.evaluation.has('special') and cfg.evaluation.special.mode == 'held':\n",
    "        #  print(all_pred_translations)\n",
    "        _, eval_dict = evaluation.evaluate_held(cfg, val_idxs, all_pred_translations, all_pred_angles, all_gt_translations, all_gt_angles, eval_dir=eval_dir, mean_time=mean_execution_time)\n",
    "    else:\n",
    "        for accept_inverted_angle, _val_writer in zip([False, True], [val_writer, val_writer_180]):\n",
    "            eval_dict = evaluation.evaluate(cfg, val_idxs, all_pred_translations, all_pred_angles, all_gt_translations, all_gt_angles, all_pred_s2_pc1centers, all_gt_pc1centers, eval_dir=eval_dir, accept_inverted_angle=accept_inverted_angle, mean_time=mean_execution_time)\n",
    "            corr_levels_translation_str = ' '.join([f'{a*100.0:.2f}%' for a in eval_dict.corr_levels_translation])\n",
    "            corr_levels_angles_str = ' '.join([f'{a*100.0:.2f}%' for a in eval_dict.corr_levels_angles])\n",
    "            corr_levels_str = ' '.join([f'{a*100.0:.2f}%' for a in eval_dict.corr_levels])\n",
    "            logger.info(f'Mean translation distance: {eval_dict.mean_dist_translation}, Mean angle distance: {eval_dict.mean_dist_angle}, Levels: {corr_levels_str}, Translation levels: {corr_levels_translation_str}, Angle levels: {corr_levels_angles_str}, Fitness: {eval_dict.reg_eval.fitness*100.0:.2f}%, Inlier RMSE: {eval_dict.reg_eval.inlier_rmse*100.0:.2f}%, Mean ex. time: {mean_execution_time:.5f}')\n",
    "\n",
    "            if not eval_only:\n",
    "                _val_writer.add_summary(summary=tf.Summary(value=[tf.summary.Summary.Value(tag='losses/loss', simple_value=mean_per_transform_loss)]), global_step=global_step)\n",
    "                _val_writer.add_summary(summary=tf.Summary(value=[tf.summary.Summary.Value(tag='accuracy/t_a_mean_dist', simple_value=eval_dict.mean_dist_translation)]), global_step=global_step)\n",
    "                _val_writer.add_summary(summary=tf.Summary(value=[tf.summary.Summary.Value(tag='accuracy/t_b_1cm', simple_value=eval_dict.corr_levels_translation[0])]), global_step=global_step)\n",
    "                _val_writer.add_summary(summary=tf.Summary(value=[tf.summary.Summary.Value(tag='accuracy/t_c_10cm', simple_value=eval_dict.corr_levels_translation[1])]), global_step=global_step)\n",
    "                _val_writer.add_summary(summary=tf.Summary(value=[tf.summary.Summary.Value(tag='accuracy/t_d_1m', simple_value=eval_dict.corr_levels_translation[2])]), global_step=global_step)\n",
    "                _val_writer.add_summary(summary=tf.Summary(value=[tf.summary.Summary.Value(tag='accuracy/a_a_mean_dist', simple_value=eval_dict.mean_dist_angle)]), global_step=global_step)\n",
    "                _val_writer.add_summary(summary=tf.Summary(value=[tf.summary.Summary.Value(tag='accuracy/a_b_1d', simple_value=eval_dict.corr_levels_angles[0])]), global_step=global_step)\n",
    "                _val_writer.add_summary(summary=tf.Summary(value=[tf.summary.Summary.Value(tag='accuracy/a_c_5d', simple_value=eval_dict.corr_levels_angles[1])]), global_step=global_step)\n",
    "                _val_writer.add_summary(summary=tf.Summary(value=[tf.summary.Summary.Value(tag='accuracy/a_d_10d', simple_value=eval_dict.corr_levels_angles[2])]), global_step=global_step)\n",
    "                _val_writer.add_summary(summary=tf.Summary(value=[tf.summary.Summary.Value(tag='accuracy/o_b_1cm', simple_value=eval_dict.corr_levels[0])]), global_step=global_step)\n",
    "                _val_writer.add_summary(summary=tf.Summary(value=[tf.summary.Summary.Value(tag='accuracy/o_c_10cm', simple_value=eval_dict.corr_levels[1])]), global_step=global_step)\n",
    "                _val_writer.add_summary(summary=tf.Summary(value=[tf.summary.Summary.Value(tag='accuracy/o_d_1m', simple_value=eval_dict.corr_levels[2])]), global_step=global_step)\n",
    "                _val_writer.add_summary(summary=tf.Summary(value=[tf.summary.Summary.Value(tag='accuracy/fitness', simple_value=eval_dict.reg_eval.fitness)]), global_step=global_step)\n",
    "                _val_writer.add_summary(summary=tf.Summary(value=[tf.summary.Summary.Value(tag='accuracy/inlier_rmse', simple_value=eval_dict.reg_eval.inlier_rmse)]), global_step=global_step)\n",
    "                _val_writer.flush()\n",
    "\n",
    "    np.save(f'{eval_dir}/pred_translations.npy', all_pred_translations)\n",
    "    np.save(f'{eval_dir}/pred_angles.npy', all_pred_angles)\n",
    "\n",
    "    np.save(f'{eval_dir}/pred_s1_pc2centers.npy', all_pred_s1_pc2centers)\n",
    "    if True or not eval_only:\n",
    "        np.save(f'{eval_dir}/pred_s1_pc1centers.npy', all_pred_s1_pc1centers)\n",
    "        np.save(f'{eval_dir}/pred_s2_pc1centers.npy', all_pred_s2_pc1centers)\n",
    "        np.save(f'{eval_dir}/pred_s2_pc2centers.npy', all_pred_s2_pc2centers)\n",
    "        np.save(f'{eval_dir}/pred_s2_pc1angles.npy', all_pred_s2_pc1angles)\n",
    "        np.save(f'{eval_dir}/pred_s2_pc2angles.npy', all_pred_s2_pc2angles)\n",
    "\n",
    "    logger.info('val mean loss: %f' % (mean_per_transform_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_learning_rate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-452aa115374c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# Get training operator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hyperparameters/learning_rate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'momentum'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_learning_rate' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "        with tf.device('/gpu:' + str(cfg.gpu_index)):\n",
    "            pcs1, pcs2, translations, rel_angles, pc1centers, pc2centers, pc1angles, pc2angles = MODEL.placeholder_inputs(cfg.training.batch_size, cfg.model.num_points)\n",
    "            is_training_pl = tf.placeholder(tf.bool, shape=())\n",
    "\n",
    "            # Note the global_step=batch parameter to minimize.\n",
    "            # That tells the optimizer to helpfully increment the 'batch' parameter for you every time it trains.\n",
    "            batch = tf.Variable(0)\n",
    "            bn_decay = get_bn_decay(batch)\n",
    "            tf.summary.scalar('hyperparameters/bn_decay', bn_decay)\n",
    "\n",
    "            # Get model and loss\n",
    "            end_points = MODEL.get_model(pcs1, pcs2, is_training_pl, bn_decay=bn_decay)\n",
    "            loss = MODEL.get_loss(pcs1, pcs2, translations, rel_angles, pc1centers, pc2centers, pc1angles, pc2angles, end_points)\n",
    "            tf.summary.scalar('losses/loss', loss)\n",
    "\n",
    "            #  correct = tf.equal(tf.argmax(pred, 1), tf.to_int64(labels_pl))\n",
    "            #  accuracy = tf.reduce_sum(tf.cast(correct, tf.float32)) / float(cfg.training.batch_size)\n",
    "            #  tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "            # Get training operator\n",
    "            learning_rate = get_learning_rate(batch)\n",
    "            tf.summary.scalar('hyperparameters/learning_rate', learning_rate)\n",
    "            if cfg.training.optimizer.optimizer == 'momentum':\n",
    "                optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=cfg.training.optimizer.momentum)\n",
    "            elif cfg.training.optimizer.optimizer == 'adam':\n",
    "                optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "            else:\n",
    "                assert False, \"Invalid optimizer\"\n",
    "            train_op = optimizer.minimize(loss, global_step=batch)\n",
    "\n",
    "            # Add ops to save and restore all the variables.\n",
    "            saver = tf.train.Saver(max_to_keep=1000)\n",
    "\n",
    "        # Create a session\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        config.allow_soft_placement = True\n",
    "        config.log_device_placement = False\n",
    "        sess = tf.Session(config=config)\n",
    "\n",
    "        # Add summary writers\n",
    "        # Documentation for summary.FileWriter:\n",
    "        # https://www.tensorflow.org/api_docs/python/tf/compat/v1/summary/FileWriter\n",
    "        # One line descriptions: Writes Summary protocol buffers to event files\n",
    "        # Params:\n",
    "        #   - logdir: (str) path to save the logs\n",
    "        #   - graph:  (tf.Graph) current Graph object\n",
    "        merged = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter(os.path.join(cfg.logging.logdir, 'train'), sess.graph)\n",
    "        val_writer = tf.summary.FileWriter(os.path.join(cfg.logging.logdir, 'val'))\n",
    "        val_writer_180 = tf.summary.FileWriter(os.path.join(cfg.logging.logdir, 'val_180'))\n",
    "\n",
    "        # Init variables\n",
    "        init = tf.global_variables_initializer()\n",
    "        # To fix the bug introduced in TF 0.12.1 as in\n",
    "        # http://stackoverflow.com/questions/41543774/invalidargumenterror-for-tensor-bool-tensorflow-0-12-1\n",
    "        # sess.run(init)\n",
    "        sess.run(init, {is_training_pl: True})\n",
    "\n",
    "        ops = {'pcs1': pcs1, 'pcs2': pcs2, 'translations': translations, 'rel_angles': rel_angles, 'is_training_pl': is_training_pl, 'pred_translations': end_points['pred_translations'], 'pred_remaining_angle_logits': end_points['pred_remaining_angle_logits'], 'pc1centers': pc1centers, 'pc2centers': pc2centers, 'pc1angles': pc1angles, 'pc2angles': pc2angles, 'pred_s1_pc1centers': end_points['pred_s1_pc1centers'], 'pred_s1_pc2centers': end_points['pred_s1_pc2centers'], 'pred_s2_pc1centers': end_points['pred_s2_pc1centers'], 'pred_s2_pc2centers': end_points['pred_s2_pc2centers'], 'pred_pc1angle_logits': end_points['pred_pc1angle_logits'], 'pred_pc2angle_logits': end_points['pred_pc2angle_logits'], 'loss': loss, 'train_op': train_op, 'merged': merged, 'step': batch}\n",
    "\n",
    "        start_epoch = 0\n",
    "        if eval_only:\n",
    "            model_to_load = cfg.logging.logdir\n",
    "            if eval_only_model_to_load is not None:\n",
    "                model_to_load = eval_only_model_to_load\n",
    "            if not FLAGS.use_old_results and not do_timings:\n",
    "                assert os.path.isfile(f'{model_to_load}/model-{eval_epoch}.index'), f'{model_to_load}/model-{eval_epoch}.index'\n",
    "                saver.restore(sess, f'{model_to_load}/model-{eval_epoch}')\n",
    "            start_epoch = int(eval_epoch)\n",
    "\n",
    "            if eval_only_model_to_load is None:\n",
    "                num_batches_per_epoch = len(TRAIN_INDICES) // cfg.training.batch_size\n",
    "\n",
    "                if FLAGS.use_old_results or do_timings:\n",
    "                    start_epoch = int(eval_epoch)\n",
    "                else:\n",
    "                    restored_batch = sess.run(batch)\n",
    "                    assert restored_batch % num_batches_per_epoch == 0\n",
    "                    start_epoch = restored_batch // num_batches_per_epoch - 1\n",
    "                    assert start_epoch == int(eval_epoch)\n",
    "            logger.info(f'Evaluating at epoch {start_epoch}')\n",
    "        else:\n",
    "            if os.path.isfile(os.path.join(cfg.logging.logdir, 'model.ckpt.index')):\n",
    "                saver.restore(sess, os.path.join(cfg.logging.logdir, 'model.ckpt'))\n",
    "\n",
    "                num_batches_per_epoch = len(TRAIN_INDICES) // cfg.training.batch_size\n",
    "\n",
    "                restored_batch = sess.run(batch)\n",
    "                assert restored_batch % num_batches_per_epoch == 0\n",
    "                start_epoch = restored_batch // num_batches_per_epoch\n",
    "                logger.info(f'Continuing training at epoch {start_epoch}')\n",
    "            elif cfg.training.pretraining.model != '':\n",
    "                assert os.path.isfile(cfg.training.pretraining.model + '.index')\n",
    "                variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "                variables_to_load = [var for var in variables if var not in [batch]]\n",
    "                saverPretraining = tf.train.Saver(variables_to_load)\n",
    "                saverPretraining.restore(sess, cfg.training.pretraining.model)\n",
    "                #  print(variables)\n",
    "                #  print(len(variables), len(variables_to_load))\n",
    "                #  varlist = print_tensors_in_checkpoint_file(file_name=cfg.training.pretraining.model, all_tensors=True, tensor_name=None)\n",
    "                #  print(varlist)\n",
    "                #  print(variables_to_load[:8])\n",
    "                #  print(len(varlist))\n",
    "                restored_batch = sess.run(batch)\n",
    "                assert restored_batch == 0\n",
    "                logger.info(f'Pre-trained weights loaded from {cfg.training.pretraining.model}, starting initial evaluation')\n",
    "                lr, bn_d = sess.run([learning_rate, bn_decay])\n",
    "                eval_one_epoch(sess, ops, val_writer, val_writer_180, 'pretr', eval_only=False, do_timings=False)\n",
    "                logger.info(f'Initial evaluation finished')\n",
    "\n",
    "        try:\n",
    "            start = time.time()\n",
    "            for epoch in range(start_epoch, cfg.training.num_epochs):\n",
    "                lr, bn_d = sess.run([learning_rate, bn_decay])\n",
    "                logger.info('**** EPOCH %03d ****    ' % (epoch) + f'lr: {lr:.8f}, bn_decay: {bn_d:.8f}')\n",
    "                #  sys.stdout.flush()\n",
    "\n",
    "                if not eval_only:\n",
    "                    train_one_epoch(sess, ops, train_writer, epoch)\n",
    "                if eval_only or True or epoch % 10 == 0: # What is going on here?\n",
    "                    if do_timings:\n",
    "                        for i in range(10):\n",
    "                            eval_one_epoch(sess, ops, val_writer, val_writer_180, epoch, eval_only=eval_only, do_timings=True, override_batch_size=override_batch_size)\n",
    "                    else:\n",
    "                        eval_one_epoch(sess, ops, val_writer, val_writer_180, epoch, eval_only=eval_only, do_timings=False)\n",
    "                if eval_only:\n",
    "                    break\n",
    "\n",
    "                if not eval_only:\n",
    "                    was_last_epoch = epoch == cfg.training.num_epochs - 1\n",
    "                    # Save the variables to disk.\n",
    "                    if epoch % 2 == 0 or was_last_epoch:\n",
    "                        save_path = saver.save(sess, os.path.join(cfg.logging.logdir, \"model.ckpt\"))\n",
    "                        logger.info(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "                    if epoch % 5 == 0 or was_last_epoch or cfg.evaluation.save_every_epoch:\n",
    "                        save_path = saver.save(sess, os.path.join(cfg.logging.logdir, \"model\"), global_step=epoch)\n",
    "                        logger.info(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "                now = time.time()\n",
    "                time_elapsed = now - start\n",
    "                time_elapsed_str = str(datetime.timedelta(seconds=time_elapsed))\n",
    "                time_remaining = time_elapsed / (epoch + 1) * (cfg.training.num_epochs - epoch - 1)\n",
    "                time_remaining_str = str(datetime.timedelta(seconds=time_remaining))\n",
    "                logger.info(f'Finished epoch {epoch}. Time elapsed: {time_elapsed_str}, Time remaining: {time_remaining_str}')\n",
    "            logger.info('Finished Training')\n",
    "        except KeyboardInterrupt:\n",
    "            logger.info('Interrupted')\n",
    "\n",
    "        is_training = False\n",
    "        batch_size = cfg.training.batch_size if override_batch_size is None else override_batch_size\n",
    "\n",
    "        val_idxs = VAL_INDICES\n",
    "        num_batches = int(np.ceil(len(val_idxs) / batch_size))\n",
    "        num_full_batches = int(np.floor(len(val_idxs) / batch_size))\n",
    "\n",
    "        loss_sum = 0\n",
    "        global_step = sess.run([ops['step']])[0]\n",
    "        #  step_in_epochs = epoch + 1\n",
    "        eval_dir = f'{cfg.logging.logdir}/val/eval{str(epoch).zfill(6)}'\n",
    "        base_eval_dir = eval_dir\n",
    "        if FLAGS.refineICP:\n",
    "            eval_dir = f'{eval_dir}/refined_{FLAGS.refineICPmethod}{\"_\"+FLAGS.its if FLAGS.its != 30 else \"\"}'\n",
    "\n",
    "        if os.path.isdir(eval_dir):\n",
    "            os.rename(eval_dir, f'{eval_dir}_backup_{int(time.time())}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
